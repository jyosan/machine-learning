<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dog_app</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Artificial-Intelligence-Nanodegree">Artificial Intelligence Nanodegree<a class="anchor-link" href="#Artificial-Intelligence-Nanodegree">&#182;</a></h1><h2 id="Convolutional-Neural-Networks">Convolutional Neural Networks<a class="anchor-link" href="#Convolutional-Neural-Networks">&#182;</a></h2><h2 id="Project:-Write-an-Algorithm-for-a-Dog-Identification-App">Project: Write an Algorithm for a Dog Identification App<a class="anchor-link" href="#Project:-Write-an-Algorithm-for-a-Dog-Identification-App">&#182;</a></h2><hr>
<p>In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with <strong>'(IMPLEMENTATION)'</strong> in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section, and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully!</p>
<blockquote><p><strong>Note</strong>: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \n",
    "<strong>File -&gt; Download as -&gt; HTML (.html)</strong>. Include the finished document along with this notebook as your submission.</p>
</blockquote>
<p>In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a <strong>'Question X'</strong> header. Carefully read each question and provide thorough answers in the following text boxes that begin with <strong>'Answer:'</strong>. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.</p>
<blockquote><p><strong>Note:</strong> Code and Markdown cells can be executed using the <strong>Shift + Enter</strong> keyboard shortcut.  Markdown cells can be edited by double-clicking the cell to enter edit mode.</p>
</blockquote>
<p>The rubric contains <em>optional</em> "Stand Out Suggestions" for enhancing the project beyond the minimum requirements. If you decide to pursue the "Stand Out Suggestions", you should include the code in this IPython notebook.</p>
<hr>
<h3 id="Why-We're-Here">Why We're Here<a class="anchor-link" href="#Why-We're-Here">&#182;</a></h3><p>In this notebook, you will make the first steps towards developing an algorithm that could be used as part of a mobile or web app.  At the end of this project, your code will accept any user-supplied image as input.  If a dog is detected in the image, it will provide an estimate of the dog's breed.  If a human is detected, it will provide an estimate of the dog breed that is most resembling.  The image below displays potential sample output of your finished project (... but we expect that each student's algorithm will behave differently!).</p>
<p><img src="images/sample_dog_output.png" alt="Sample Dog Output"></p>
<p>In this real-world setting, you will need to piece together a series of models to perform different tasks; for instance, the algorithm that detects humans in an image will be different from the CNN that infers dog breed.  There are many points of possible failure, and no perfect algorithm exists.  Your imperfect solution will nonetheless create a fun user experience!</p>
<h3 id="The-Road-Ahead">The Road Ahead<a class="anchor-link" href="#The-Road-Ahead">&#182;</a></h3><p>We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.</p>
<ul>
<li><a href="#step0">Step 0</a>: Import Datasets</li>
<li><a href="#step1">Step 1</a>: Detect Humans</li>
<li><a href="#step2">Step 2</a>: Detect Dogs</li>
<li><a href="#step3">Step 3</a>: Create a CNN to Classify Dog Breeds (from Scratch)</li>
<li><a href="#step4">Step 4</a>: Use a CNN to Classify Dog Breeds (using Transfer Learning)</li>
<li><a href="#step5">Step 5</a>: Create a CNN to Classify Dog Breeds (using Transfer Learning)</li>
<li><a href="#step6">Step 6</a>: Write your Algorithm</li>
<li><a href="#step7">Step 7</a>: Test Your Algorithm</li>
</ul>
<hr>
<p><a id='step0'></a></p>
<h2 id="Step-0:-Import-Datasets">Step 0: Import Datasets<a class="anchor-link" href="#Step-0:-Import-Datasets">&#182;</a></h2><h3 id="Import-Dog-Dataset">Import Dog Dataset<a class="anchor-link" href="#Import-Dog-Dataset">&#182;</a></h3><p>In the code cell below, we import a dataset of dog images.  We populate a few variables through the use of the <code>load_files</code> function from the scikit-learn library:</p>
<ul>
<li><code>train_files</code>, <code>valid_files</code>, <code>test_files</code> - numpy arrays containing file paths to images</li>
<li><code>train_targets</code>, <code>valid_targets</code>, <code>test_targets</code> - numpy arrays containing onehot-encoded classification labels </li>
<li><code>dog_names</code> - list of string-valued dog breed names for translating labels</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_files</span>       
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">np_utils</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="k">import</span> <span class="n">glob</span>

<span class="c1"># define function to load train, test, and validation datasets</span>
<span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">load_files</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">dog_files</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;filenames&#39;</span><span class="p">])</span>
    <span class="n">dog_targets</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]),</span> <span class="mi">133</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dog_files</span><span class="p">,</span> <span class="n">dog_targets</span>

<span class="c1"># load train, test, and validation datasets</span>
<span class="n">train_files</span><span class="p">,</span> <span class="n">train_targets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;/dogImages/dogImages/train&#39;</span><span class="p">)</span>
<span class="n">valid_files</span><span class="p">,</span> <span class="n">valid_targets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;/dogImages/dogImages/valid&#39;</span><span class="p">)</span>
<span class="n">test_files</span><span class="p">,</span> <span class="n">test_targets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;/dogImages/dogImages/test&#39;</span><span class="p">)</span>

<span class="c1"># load list of dog names</span>
<span class="n">dog_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">20</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;/dogImages/dogImages/train/*/&quot;</span><span class="p">))]</span>

<span class="c1"># print statistics about the dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> total dog categories.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">dog_names</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%s</span><span class="s1"> total dog images.</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">train_files</span><span class="p">,</span> <span class="n">valid_files</span><span class="p">,</span> <span class="n">test_files</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> training dog images.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_files</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> validation dog images.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_files</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> test dog images.&#39;</span><span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_files</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>There are 133 total dog categories.
There are 8351 total dog images.

There are 6680 training dog images.
There are 835 validation dog images.
There are 836 test dog images.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Import-Human-Dataset">Import Human Dataset<a class="anchor-link" href="#Import-Human-Dataset">&#182;</a></h3><p>In the code cell below, we import a dataset of human images, where the file paths are stored in the numpy array <code>human_files</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">8675309</span><span class="p">)</span>

<span class="c1"># load filenames in shuffled human dataset</span>
<span class="n">human_files</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;/lfw/*/*&quot;</span><span class="p">))</span>
<span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">human_files</span><span class="p">)</span>

<span class="c1"># print statistics about the dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;There are </span><span class="si">%d</span><span class="s1"> total human images.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">human_files</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>There are 13233 total human images.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step1'></a></p>
<h2 id="Step-1:-Detect-Humans">Step 1: Detect Humans<a class="anchor-link" href="#Step-1:-Detect-Humans">&#182;</a></h2><p>We use OpenCV's implementation of <a href="http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html">Haar feature-based cascade classifiers</a> to detect human faces in images.  OpenCV provides many pre-trained face detectors, stored as XML files on <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">github</a>.  We have downloaded one of these detectors and stored it in the <code>haarcascades</code> directory.</p>
<p>In the next code cell, we demonstrate how to use this detector to find human faces in a sample image.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>                
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>                        
<span class="o">%</span><span class="k">matplotlib</span> inline                               

<span class="c1"># extract pre-trained face detector</span>
<span class="n">face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s1">&#39;/harcascades/haarcascade_frontalface_alt.xml&#39;</span><span class="p">)</span>

<span class="c1"># load color (BGR) image</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">human_files</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="c1"># convert BGR image to grayscale</span>
<span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="c1"># find faces in image</span>
<span class="n">faces</span> <span class="o">=</span> <span class="n">face_cascade</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">)</span>

<span class="c1"># print number of faces detected in the image</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of faces detected:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">faces</span><span class="p">))</span>

<span class="c1"># get bounding box for each detected face</span>
<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
    <span class="c1"># add bounding box to color image</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">),(</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
    
<span class="c1"># convert BGR image to RGB for plotting</span>
<span class="n">cv_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>

<span class="c1"># display the image, along with bounding box</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv_rgb</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of faces detected: 1
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before using any of the face detectors, it is standard procedure to convert the images to grayscale.  The <code>detectMultiScale</code> function executes the classifier stored in <code>face_cascade</code> and takes the grayscale image as a parameter.</p>
<p>In the above code, <code>faces</code> is a numpy array of detected faces, where each row corresponds to a detected face.  Each detected face is a 1D array with four entries that specifies the bounding box of the detected face.  The first two entries in the array (extracted in the above code as <code>x</code> and <code>y</code>) specify the horizontal and vertical positions of the top left corner of the bounding box.  The last two entries in the array (extracted here as <code>w</code> and <code>h</code>) specify the width and height of the box.</p>
<h3 id="Write-a-Human-Face-Detector">Write a Human Face Detector<a class="anchor-link" href="#Write-a-Human-Face-Detector">&#182;</a></h3><p>We can use this procedure to write a function that returns <code>True</code> if a human face is detected in an image and <code>False</code> otherwise.  This function, aptly named <code>face_detector</code>, takes a string-valued file path to an image as input and appears in the code block below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># returns &quot;True&quot; if face is detected in image stored at img_path</span>
<span class="k">def</span> <span class="nf">face_detector</span><span class="p">(</span><span class="n">img_path</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
    <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
    <span class="n">faces</span> <span class="o">=</span> <span class="n">face_cascade</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">faces</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Assess-the-Human-Face-Detector">(IMPLEMENTATION) Assess the Human Face Detector<a class="anchor-link" href="#(IMPLEMENTATION)-Assess-the-Human-Face-Detector">&#182;</a></h3><p><strong>Question 1:</strong> Use the code cell below to test the performance of the <code>face_detector</code> function.</p>
<ul>
<li>What percentage of the first 100 images in <code>human_files</code> have a detected human face?  </li>
<li>What percentage of the first 100 images in <code>dog_files</code> have a detected human face? </li>
</ul>
<p>Ideally, we would like 100% of human images with a detected face and 0% of dog images with a detected face.  You will see that our algorithm falls short of this goal, but still gives acceptable performance.  We extract the file paths for the first 100 images from each of the datasets and store them in the numpy arrays <code>human_files_short</code> and <code>dog_files_short</code>.</p>
<p><strong>Answer:</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">human_files_short</span> <span class="o">=</span> <span class="n">human_files</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
<span class="n">dog_files_short</span> <span class="o">=</span> <span class="n">train_files</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
<span class="c1"># Do NOT modify the code above this line.</span>
<span class="n">yhum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">)</span>
<span class="n">ydog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">)</span>
<span class="n">a</span><span class="o">=</span><span class="mi">0</span>
<span class="n">b</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">human_files_short</span><span class="p">)):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">face_detector</span><span class="p">(</span><span class="n">human_files_short</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c1">#print(k)</span>
    <span class="n">yhum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yhum</span><span class="p">,</span><span class="n">k</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dog_files_short</span><span class="p">)):</span>
    <span class="n">j</span><span class="o">=</span> <span class="n">face_detector</span><span class="p">(</span><span class="n">dog_files_short</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
    <span class="c1">#print(j)</span>
    <span class="n">ydog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ydog</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">yhum</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ydog</span><span class="p">)</span>
<span class="n">humpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">yhum</span><span class="p">)</span>
<span class="c1">#humneg = np.count_zero(yhum)</span>
<span class="n">dogpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ydog</span><span class="p">)</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;human positive &quot;</span> <span class="p">,</span> <span class="n">humpos</span><span class="p">)</span>
<span class="c1">#print(&quot;human negative &quot; , humpos)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dog positive &quot;</span> <span class="p">,</span> <span class="n">dogpos</span><span class="p">)</span>

<span class="c1"># this is the count of dog faces that were detected as false by the human face detector which is correct since they are faces of dogs</span>
<span class="n">dogneg</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">dogpos</span>
    
    
<span class="c1">## TODO: Test the performance of the face_detector algorithm </span>
<span class="c1">## on the images in human_files_short and dog_files_short.</span>
<span class="n">hacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">humpos</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span><span class="mi">100</span>
<span class="n">dacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">dogneg</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span><span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;accuracy </span><span class="si">% o</span><span class="s2">n human &quot;</span> <span class="p">,</span> <span class="n">hacc</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;accuracy </span><span class="si">% o</span><span class="s2">n dog &quot;</span><span class="p">,</span>  <span class="n">dacc</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[ True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True]
[ True False False False False False False False False False False False
 False False  True  True False False False False False  True  True  True
  True False False False False False  True False  True False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False  True False False False False False False False False
 False False False False False False  True False False False False False
 False False False False False False False False False False False False
 False False False False]
human positive  100
dog positive  11
accuracy % on human  100.0
accuracy % on dog  89.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Question 2:</strong> This algorithmic choice necessitates that we communicate to the user that we accept human images only when they provide a clear view of a face (otherwise, we risk having unneccessarily frustrated users!). In your opinion, is this a reasonable expectation to pose on the user? If not, can you think of a way to detect humans in images that does not necessitate an image with a clearly presented face?</p>
<p><strong>Answer:</strong>
The results show that the classifier is accurate 99% of the time for humans but does not meet the same goal for dogs and is only 89% accurate it also requires that the image should be clear. This makes it less flexible for the users. Instead an algorithm which can first detect the important features based on human faces and then be trained on features for dogs like the large ears etc will be helpful.
Also if the algorithm first screens for main features that can clearly distinguish a human from a dog first then the whole image need not be passed thru the NN it can determine in the first output if the image is not a human.
One such algorithm that i found was MTCNN 
<a href="https://medium.com/wassa/modern-face-detection-based-on-deep-learning-using-python-and-mxnet-5e6377f22674">https://medium.com/wassa/modern-face-detection-based-on-deep-learning-using-python-and-mxnet-5e6377f22674</a></p>
<p>The MTCNN has 3 NNs in the first pass it eliminates the obviously false images that can easily be identified
The second NN uses the results of the first and eliminates more false images that are not human
The third NN uses the results from the second and refines the images and identifies positions of features.</p>
<p>We suggest the face detector from OpenCV as a potential way to detect human images in your algorithm, but you are free to explore other approaches, especially approaches that make use of deep learning :).  Please use the code cell below to design and test your own face detection algorithm.  If you decide to pursue this <em>optional</em> task, report performance on each of the datasets.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## (Optional) TODO: Report the performance of another  </span>
<span class="c1">## face detection algorithm on the LFW dataset</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>
<span class="c1">#import cv2                </span>
<span class="c1">#import matplotlib.pyplot as plt   </span>
<span class="c1">#import mxnet as mx</span>

<span class="c1">#%matplotlib inline  </span>
<span class="c1">#hfiles = np.array(glob(&quot;/lfw/*/*&quot;))</span>
<span class="c1"># load color (BGR) image</span>
<span class="c1">#himg = cv2.imread(human_files[])</span>
<span class="c1"># convert BGR image to grayscale</span>
<span class="c1">#gray = cv2.cvtColor(himg, cv2.COLOR_BGR2GRAY)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step2'></a></p>
<h2 id="Step-2:-Detect-Dogs">Step 2: Detect Dogs<a class="anchor-link" href="#Step-2:-Detect-Dogs">&#182;</a></h2><p>In this section, we use a pre-trained <a href="http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006">ResNet-50</a> model to detect dogs in images.  Our first line of code downloads the ResNet-50 model, along with weights that have been trained on <a href="http://www.image-net.org/">ImageNet</a>, a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of <a href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a">1000 categories</a>.  Given an image, this pre-trained ResNet-50 model returns a prediction (derived from the available categories in ImageNet) for the object that is contained in the image.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.applications.resnet50</span> <span class="k">import</span> <span class="n">ResNet50</span>

<span class="c1"># define ResNet50 model</span>
<span class="n">ResNet50_model</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5
102359040/102853048 [============================&gt;.] - ETA: 0s</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pre-process-the-Data">Pre-process the Data<a class="anchor-link" href="#Pre-process-the-Data">&#182;</a></h3><p>When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape</p>
$$
(\text{nb_samples}, \text{rows}, \text{columns}, \text{channels}),
$$<p>where <code>nb_samples</code> corresponds to the total number of images (or samples), and <code>rows</code>, <code>columns</code>, and <code>channels</code> correspond to the number of rows, columns, and channels for each image, respectively.</p>
<p>The <code>path_to_tensor</code> function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN.  The function first loads the image and resizes it to a square image that is $224 \times 224$ pixels.  Next, the image is converted to an array, which is then resized to a 4D tensor.  In this case, since we are working with color images, each image has three channels.  Likewise, since we are processing a single image (or sample), the returned tensor will always have shape</p>
$$
(1, 224, 224, 3).
$$<p>The <code>paths_to_tensor</code> function takes a numpy array of string-valued image paths as input and returns a 4D tensor with shape</p>
$$
(\text{nb_samples}, 224, 224, 3).
$$<p>Here, <code>nb_samples</code> is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of <code>nb_samples</code> as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="k">import</span> <span class="n">image</span>                  
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">path_to_tensor</span><span class="p">(</span><span class="n">img_path</span><span class="p">):</span>
    <span class="c1"># loads RGB image as PIL.Image.Image type</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
    <span class="c1"># convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="c1"># convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">paths_to_tensor</span><span class="p">(</span><span class="n">img_paths</span><span class="p">):</span>
    <span class="n">list_of_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">path_to_tensor</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span> <span class="k">for</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">img_paths</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">list_of_tensors</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Making-Predictions-with-ResNet-50">Making Predictions with ResNet-50<a class="anchor-link" href="#Making-Predictions-with-ResNet-50">&#182;</a></h3><p>Getting the 4D tensor ready for ResNet-50, and for any other pre-trained model in Keras, requires some additional processing.  First, the RGB image is converted to BGR by reordering the channels.  All pre-trained models have the additional normalization step that the mean pixel (expressed in RGB as $[103.939, 116.779, 123.68]$ and calculated from all pixels in all images in ImageNet) must be subtracted from every pixel in each image.  This is implemented in the imported function <code>preprocess_input</code>.  If you're curious, you can check the code for <code>preprocess_input</code> <a href="https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py">here</a>.</p>
<p>Now that we have a way to format our image for supplying to ResNet-50, we are now ready to use the model to extract the predictions.  This is accomplished with the <code>predict</code> method, which returns an array whose $i$-th entry is the model's predicted probability that the image belongs to the $i$-th ImageNet category.  This is implemented in the <code>ResNet50_predict_labels</code> function below.</p>
<p>By taking the argmax of the predicted probability vector, we obtain an integer corresponding to the model's predicted object class, which we can identify with an object category through the use of this <a href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a">dictionary</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.applications.resnet50</span> <span class="k">import</span> <span class="n">preprocess_input</span><span class="p">,</span> <span class="n">decode_predictions</span>

<span class="k">def</span> <span class="nf">ResNet50_predict_labels</span><span class="p">(</span><span class="n">img_path</span><span class="p">):</span>
    <span class="c1"># returns prediction vector for image located at img_path</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">preprocess_input</span><span class="p">(</span><span class="n">path_to_tensor</span><span class="p">(</span><span class="n">img_path</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ResNet50_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Write-a-Dog-Detector">Write a Dog Detector<a class="anchor-link" href="#Write-a-Dog-Detector">&#182;</a></h3><p>While looking at the <a href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a">dictionary</a>, you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from <code>'Chihuahua'</code> to <code>'Mexican hairless'</code>.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained ResNet-50 model, we need only check if the <code>ResNet50_predict_labels</code> function above returns a value between 151 and 268 (inclusive).</p>
<p>We use these ideas to complete the <code>dog_detector</code> function below, which returns <code>True</code> if a dog is detected in an image (and <code>False</code> if not).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### returns &quot;True&quot; if a dog is detected in the image stored at img_path</span>
<span class="k">def</span> <span class="nf">dog_detector</span><span class="p">(</span><span class="n">img_path</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">ResNet50_predict_labels</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">prediction</span> <span class="o">&lt;=</span> <span class="mi">268</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">&gt;=</span> <span class="mi">151</span><span class="p">))</span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Assess-the-Dog-Detector">(IMPLEMENTATION) Assess the Dog Detector<a class="anchor-link" href="#(IMPLEMENTATION)-Assess-the-Dog-Detector">&#182;</a></h3><p><strong>Question 3:</strong> Use the code cell below to test the performance of your <code>dog_detector</code> function.</p>
<ul>
<li>What percentage of the images in <code>human_files_short</code> have a detected dog?  </li>
<li>What percentage of the images in <code>dog_files_short</code> have a detected dog?</li>
</ul>
<p><strong>Answer:</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Test the performance of the dog_detector function</span>
<span class="c1">### on the images in human_files_short and dog_files_short.</span>
<span class="n">yhum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">)</span>
<span class="n">ydog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span><span class="n">dtype</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">)</span>
<span class="n">a</span><span class="o">=</span><span class="mi">0</span>
<span class="n">b</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">human_files_short</span><span class="p">)):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">dog_detector</span><span class="p">(</span><span class="n">human_files_short</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c1">#print(k)</span>
    <span class="n">yhum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yhum</span><span class="p">,</span><span class="n">k</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dog_files_short</span><span class="p">)):</span>
    <span class="n">j</span><span class="o">=</span> <span class="n">dog_detector</span><span class="p">(</span><span class="n">dog_files_short</span><span class="p">[</span><span class="n">l</span><span class="p">])</span>
    <span class="c1">#print(j)</span>
    <span class="n">ydog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ydog</span><span class="p">,</span><span class="n">j</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">yhum</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ydog</span><span class="p">)</span>
<span class="n">humpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">yhum</span><span class="p">)</span>
<span class="c1">#humneg = np.count_zero(yhum)</span>
<span class="n">dogpos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ydog</span><span class="p">)</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;human positive &quot;</span> <span class="p">,</span> <span class="n">humpos</span><span class="p">)</span>
<span class="c1">#print(&quot;human negative &quot; , humpos)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dog positive &quot;</span> <span class="p">,</span> <span class="n">dogpos</span><span class="p">)</span>

<span class="c1"># this is the count of human faces that were detected as false by the dog face detector which is correct since they are faces of humans</span>
<span class="n">humneg</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">humpos</span>
    
    
<span class="c1">## TODO: Test the performance of the dog face_detector algorithm </span>
<span class="c1">## on the images in human_files_short and dog_files_short.</span>
<span class="n">hacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">humneg</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span><span class="mi">100</span>
<span class="n">dacc</span> <span class="o">=</span> <span class="p">(</span><span class="n">dogpos</span><span class="o">/</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span><span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;accuracy </span><span class="si">% o</span><span class="s2">n human &quot;</span> <span class="p">,</span> <span class="n">hacc</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;accuracy </span><span class="si">% o</span><span class="s2">n dog &quot;</span><span class="p">,</span>  <span class="n">dacc</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False  True False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False]
[ True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True]
human positive  1
dog positive  100
accuracy % on human  99.0
accuracy % on dog  100.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step3'></a></p>
<h2 id="Step-3:-Create-a-CNN-to-Classify-Dog-Breeds-(from-Scratch)">Step 3: Create a CNN to Classify Dog Breeds (from Scratch)<a class="anchor-link" href="#Step-3:-Create-a-CNN-to-Classify-Dog-Breeds-(from-Scratch)">&#182;</a></h2><p>Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, you will create a CNN that classifies dog breeds.  You must create your CNN <em>from scratch</em> (so, you can't use transfer learning <em>yet</em>!), and you must attain a test accuracy of at least 1%.  In Step 5 of this notebook, you will have the opportunity to use transfer learning to create a CNN that attains greatly improved accuracy.</p>
<p>Be careful with adding too many trainable layers!  More parameters means longer training, which means you are more likely to need a GPU to accelerate the training process.  Thankfully, Keras provides a handy estimate of the time that each epoch is likely to take; you can extrapolate this estimate to figure out how long it will take for your algorithm to train.</p>
<p>We mention that the task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that <em>even a human</em> would have great difficulty in distinguishing between a Brittany and a Welsh Springer Spaniel.</p>
<table>
<thead><tr>
<th>Brittany</th>
<th>Welsh Springer Spaniel</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="images/Brittany_02625.jpg" width="100"></td>
<td><img src="images/Welsh_springer_spaniel_08203.jpg" width="200"></td>
</tr>
</tbody>
</table>
<p>It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).</p>
<table>
<thead><tr>
<th>Curly-Coated Retriever</th>
<th>American Water Spaniel</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="images/Curly-coated_retriever_03896.jpg" width="200"></td>
<td><img src="images/American_water_spaniel_00648.jpg" width="200"></td>
</tr>
</tbody>
</table>
<p>Likewise, recall that labradors come in yellow, chocolate, and black.  Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.</p>
<table>
<thead><tr>
<th>Yellow Labrador</th>
<th>Chocolate Labrador</th>
<th>Black Labrador</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="images/Labrador_retriever_06457.jpg" width="150"></td>
<td><img src="images/Labrador_retriever_06455.jpg" width="240"></td>
<td><img src="images/Labrador_retriever_06449.jpg" width="220"></td>
</tr>
</tbody>
</table>
<p>We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.</p>
<p>Remember that the practice is far ahead of the theory in deep learning.  Experiment with many different architectures, and trust your intuition.  And, of course, have fun!</p>
<h3 id="Pre-process-the-Data">Pre-process the Data<a class="anchor-link" href="#Pre-process-the-Data">&#182;</a></h3><p>We rescale the images by dividing every pixel in every image by 255.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">ImageFile</span>                            
<span class="n">ImageFile</span><span class="o">.</span><span class="n">LOAD_TRUNCATED_IMAGES</span> <span class="o">=</span> <span class="kc">True</span>                 

<span class="c1"># pre-process the data for Keras</span>
<span class="n">train_tensors</span> <span class="o">=</span> <span class="n">paths_to_tensor</span><span class="p">(</span><span class="n">train_files</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>
<span class="n">valid_tensors</span> <span class="o">=</span> <span class="n">paths_to_tensor</span><span class="p">(</span><span class="n">valid_files</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>
<span class="n">test_tensors</span> <span class="o">=</span> <span class="n">paths_to_tensor</span><span class="p">(</span><span class="n">test_files</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|| 6680/6680 [00:54&lt;00:00, 122.67it/s]
100%|| 835/835 [00:06&lt;00:00, 135.49it/s]
100%|| 836/836 [00:06&lt;00:00, 137.51it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Model-Architecture">(IMPLEMENTATION) Model Architecture<a class="anchor-link" href="#(IMPLEMENTATION)-Model-Architecture">&#182;</a></h3><p>Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:</p>

<pre><code>    model.summary()

</code></pre>
<p>We have imported some Python modules to get you started, but feel free to import as many modules as you need.  If you end up getting stuck, here's a hint that specifies a model that trains relatively fast on CPU and attains &gt;1% test accuracy in 5 epochs:</p>
<p><img src="images/sample_cnn.png" alt="Sample CNN"></p>
<p><strong>Question 4:</strong> Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  If you chose to use the hinted architecture above, describe why you think that CNN architecture should work well for the image classification task.</p>
<p><strong>Answer:</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### ANSWER - define model architecture </span>
<span class="c1">### I tried other architectures and my accuracy was not consistent sometimes it was slightly greater that 1% and mostly </span>
<span class="c1">###less than 1%. There were some reasons, my guess is as follows : </span>
<span class="c1"># 1 try had the filter size (5,5) - this could have been too large</span>
<span class="c1"># 2nd try used some drop outs to avoid overfitting on the test set </span>
<span class="c1"># 3rd try changed the activation functions alternatively between tanh and relu</span>
<span class="c1"># 4th try increased the number of filters randomly - this was not correct so i re-read the training</span>
<span class="c1"># 5th try attemped to add 1 fully connected layer at the end and flatter </span>
<span class="c1"># 6th try finally attempted to simulate udacity model - the accuracy is good</span>
    <span class="c1"># In the udacity model first layer - we first add 16 Conv 2D filters </span>
    <span class="c1"># 2nd layer we reduce the h , w by half while preserving the filters by using a max pooling layer. This helps with reducing overfitting the model to the test set</span>
    <span class="c1"># 3rd layer we increase the number of filters to 32 . This helps with identifying refined features (possibly edges , curves)</span>
    <span class="c1"># 4th layer we add more max pooling to keep the h , w from increasing which keeps it @ 55</span>
    <span class="c1"># 5th layer we add another conv 2d layer by increasing the number of filter to 64 . This may be used to identify features like ears, tail , eyes etc</span>
    <span class="c1"># 6th layer again we add a max pooling layer to reduce h, w which is now 27</span>
    <span class="c1"># 7th layer we add a Global Average Pooling which gets the average of each feature filter there by reducing into a single vector</span>
    <span class="c1"># 8th layer the final layer uses a softmax funtion to understand get the probability of classification of the 133 dog breeds </span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">GlobalAveragePooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">train_tensors</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_tensors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span><span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="c1">#model.add(Flatten())</span>
<span class="c1">#odel.add(Dense(1000, activation=&#39;relu&#39;))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GlobalAveragePooling2D</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">133</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="c1">### TODO: Define your architecture. - in the above cell</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;numpy.ndarray&#39;&gt;
(6680, 224, 224, 3)
[[[ 0.63137257  0.38431373  0.01960784]
  [ 0.63529414  0.3882353   0.02352941]
  [ 0.63137257  0.38431373  0.01176471]
  ..., 
  [ 0.47450981  0.08627451  0.00392157]
  [ 0.44705883  0.08627451  0.        ]
  [ 0.47058824  0.10980392  0.01960784]]

 [[ 0.63529414  0.3882353   0.02352941]
  [ 0.63137257  0.38431373  0.01960784]
  [ 0.63921571  0.39215687  0.01960784]
  ..., 
  [ 0.48627451  0.09019608  0.01176471]
  [ 0.4509804   0.08235294  0.        ]
  [ 0.47450981  0.10588235  0.00784314]]

 [[ 0.63529414  0.3882353   0.02352941]
  [ 0.627451    0.38039216  0.01568628]
  [ 0.64313728  0.39607844  0.02352941]
  ..., 
  [ 0.48627451  0.09019608  0.01176471]
  [ 0.44313726  0.06666667  0.        ]
  [ 0.4627451   0.08627451  0.        ]]

 ..., 
 [[ 0.21176471  0.10980392  0.05098039]
  [ 0.21568628  0.11372549  0.05490196]
  [ 0.19607843  0.10588235  0.04313726]
  ..., 
  [ 0.21568628  0.10588235  0.10196079]
  [ 0.23921569  0.11372549  0.07058824]
  [ 0.25490198  0.12941177  0.08627451]]

 [[ 0.20392157  0.10196079  0.04313726]
  [ 0.21176471  0.10980392  0.05098039]
  [ 0.19607843  0.10588235  0.04313726]
  ..., 
  [ 0.19607843  0.08627451  0.08235294]
  [ 0.22352941  0.09803922  0.05490196]
  [ 0.24313726  0.11764706  0.07450981]]

 [[ 0.19607843  0.09411765  0.03529412]
  [ 0.22352941  0.12156863  0.0627451 ]
  [ 0.20392157  0.11372549  0.05098039]
  ..., 
  [ 0.14117648  0.04313726  0.02745098]
  [ 0.19215687  0.07450981  0.04313726]
  [ 0.20784314  0.09019608  0.05882353]]]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 223, 223, 16)      208       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 111, 111, 16)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 110, 110, 32)      2080      
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 55, 55, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 54, 54, 64)        8256      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 27, 27, 64)        0         
_________________________________________________________________
global_average_pooling2d_1 ( (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 133)               8645      
=================================================================
Total params: 19,189
Trainable params: 19,189
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compile-the-Model">Compile the Model<a class="anchor-link" href="#Compile-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Train-the-Model">(IMPLEMENTATION) Train the Model<a class="anchor-link" href="#(IMPLEMENTATION)-Train-the-Model">&#182;</a></h3><p>Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.</p>
<p>You are welcome to <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html">augment the training data</a>, but this is not a requirement.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span>  

<span class="c1">### TODO: specify the number of epochs that you would like to use to train the model.</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1">### Do NOT modify the code below this line.</span>

<span class="c1">#checkpointer = ModelCheckpoint(filepath=&#39;/saved_models/weights.best.from_scratch.hdf5&#39;, </span>
<span class="c1">#                               verbose=1, save_best_only=True)</span>
<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;/output/weights.best.from_scratch.hdf5&#39;</span><span class="p">,</span> 
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_tensors</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> 
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_tensors</span><span class="p">,</span> <span class="n">valid_targets</span><span class="p">),</span>
          <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 6680 samples, validate on 835 samples
Epoch 1/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.8824 - acc: 0.0102Epoch 00000: val_loss improved from inf to 4.86935, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 21s - loss: 4.8825 - acc: 0.0102 - val_loss: 4.8693 - val_acc: 0.0084
Epoch 2/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.8671 - acc: 0.0119Epoch 00001: val_loss improved from 4.86935 to 4.85439, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 20s - loss: 4.8672 - acc: 0.0118 - val_loss: 4.8544 - val_acc: 0.0168
Epoch 3/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.8417 - acc: 0.0158Epoch 00002: val_loss improved from 4.85439 to 4.82089, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 21s - loss: 4.8417 - acc: 0.0157 - val_loss: 4.8209 - val_acc: 0.0156
Epoch 4/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.7964 - acc: 0.0198Epoch 00003: val_loss improved from 4.82089 to 4.78532, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 21s - loss: 4.7963 - acc: 0.0198 - val_loss: 4.7853 - val_acc: 0.0180
Epoch 5/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.7542 - acc: 0.0206Epoch 00004: val_loss improved from 4.78532 to 4.76913, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 20s - loss: 4.7545 - acc: 0.0205 - val_loss: 4.7691 - val_acc: 0.0275
Epoch 6/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.7278 - acc: 0.0227Epoch 00005: val_loss improved from 4.76913 to 4.75233, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 21s - loss: 4.7277 - acc: 0.0226 - val_loss: 4.7523 - val_acc: 0.0132
Epoch 7/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.7061 - acc: 0.0285Epoch 00006: val_loss improved from 4.75233 to 4.74270, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 21s - loss: 4.7056 - acc: 0.0284 - val_loss: 4.7427 - val_acc: 0.0180
Epoch 8/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.6888 - acc: 0.0284Epoch 00007: val_loss improved from 4.74270 to 4.73020, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 20s - loss: 4.6888 - acc: 0.0283 - val_loss: 4.7302 - val_acc: 0.0263
Epoch 9/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.6709 - acc: 0.0284Epoch 00008: val_loss improved from 4.73020 to 4.71766, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 20s - loss: 4.6710 - acc: 0.0286 - val_loss: 4.7177 - val_acc: 0.0263
Epoch 10/10
6660/6680 [============================&gt;.] - ETA: 0s - loss: 4.6548 - acc: 0.0309Epoch 00009: val_loss improved from 4.71766 to 4.70144, saving model to /output/weights.best.from_scratch.hdf5
6680/6680 [==============================] - 20s - loss: 4.6546 - acc: 0.0310 - val_loss: 4.7014 - val_acc: 0.0192
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[18]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x7fabcef94f28&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-Model-with-the-Best-Validation-Loss">Load the Model with the Best Validation Loss<a class="anchor-link" href="#Load-the-Model-with-the-Best-Validation-Loss">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;/output/weights.best.from_scratch.hdf5&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-the-Model">Test the Model<a class="anchor-link" href="#Test-the-Model">&#182;</a></h3><p>Try out your model on the test dataset of dog images.  Ensure that your test accuracy is greater than 1%.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get index of predicted dog breed for each image in test set</span>
<span class="n">dog_breed_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">test_tensors</span><span class="p">]</span>

<span class="c1"># report test accuracy</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dog_breed_predictions</span><span class="p">)</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_targets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">dog_breed_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: </span><span class="si">%.4f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">test_accuracy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test accuracy: 2.9904%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step4'></a></p>
<h2 id="Step-4:-Use-a-CNN-to-Classify-Dog-Breeds">Step 4: Use a CNN to Classify Dog Breeds<a class="anchor-link" href="#Step-4:-Use-a-CNN-to-Classify-Dog-Breeds">&#182;</a></h2><p>To reduce training time without sacrificing accuracy, we show you how to train a CNN using transfer learning.  In the following step, you will get a chance to use transfer learning to train your own CNN.</p>
<h3 id="Obtain-Bottleneck-Features">Obtain Bottleneck Features<a class="anchor-link" href="#Obtain-Bottleneck-Features">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bottleneck_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/bottleneck_features/DogVGG16Data.npz&#39;</span><span class="p">)</span>
<span class="n">train_VGG16</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
<span class="n">valid_VGG16</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">]</span>
<span class="n">test_VGG16</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-Architecture">Model Architecture<a class="anchor-link" href="#Model-Architecture">&#182;</a></h3><p>The model uses the the pre-trained VGG-16 model as a fixed feature extractor, where the last convolutional output of VGG-16 is fed as input to our model.  We only add a global average pooling layer and a fully connected layer, where the latter contains one node for each dog category and is equipped with a softmax.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">VGG16_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">VGG16_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">train_VGG16</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">VGG16_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">133</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">VGG16_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d_2 ( (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 133)               68229     
=================================================================
Total params: 68,229
Trainable params: 68,229
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compile-the-Model">Compile the Model<a class="anchor-link" href="#Compile-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">VGG16_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-the-Model">Train the Model<a class="anchor-link" href="#Train-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;/output/weights.best.VGG16.hdf5&#39;</span><span class="p">,</span> 
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">VGG16_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_VGG16</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> 
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_VGG16</span><span class="p">,</span> <span class="n">valid_targets</span><span class="p">),</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 6680 samples, validate on 835 samples
Epoch 1/20
6600/6680 [============================&gt;.] - ETA: 0s - loss: 12.3639 - acc: 0.1291Epoch 00000: val_loss improved from inf to 10.84123, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 12.3231 - acc: 0.1316 - val_loss: 10.8412 - val_acc: 0.2168
Epoch 2/20
6620/6680 [============================&gt;.] - ETA: 0s - loss: 10.4378 - acc: 0.2734Epoch 00001: val_loss improved from 10.84123 to 10.22867, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 10.4182 - acc: 0.2750 - val_loss: 10.2287 - val_acc: 0.2790
Epoch 3/20
6560/6680 [============================&gt;.] - ETA: 0s - loss: 9.8828 - acc: 0.3297Epoch 00002: val_loss improved from 10.22867 to 9.79045, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 9.8925 - acc: 0.3293 - val_loss: 9.7904 - val_acc: 0.3305
Epoch 4/20
6580/6680 [============================&gt;.] - ETA: 0s - loss: 9.5178 - acc: 0.3711Epoch 00003: val_loss improved from 9.79045 to 9.75657, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 9.5096 - acc: 0.3710 - val_loss: 9.7566 - val_acc: 0.3353
Epoch 5/20
6580/6680 [============================&gt;.] - ETA: 0s - loss: 9.3743 - acc: 0.3883Epoch 00004: val_loss improved from 9.75657 to 9.63596, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 9.3696 - acc: 0.3879 - val_loss: 9.6360 - val_acc: 0.3329
Epoch 6/20
6640/6680 [============================&gt;.] - ETA: 0s - loss: 9.1726 - acc: 0.4050Epoch 00005: val_loss improved from 9.63596 to 9.45299, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 9.1852 - acc: 0.4043 - val_loss: 9.4530 - val_acc: 0.3593
Epoch 7/20
6520/6680 [============================&gt;.] - ETA: 0s - loss: 9.0650 - acc: 0.4158Epoch 00006: val_loss improved from 9.45299 to 9.39130, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 9.0608 - acc: 0.4154 - val_loss: 9.3913 - val_acc: 0.3473
Epoch 8/20
6640/6680 [============================&gt;.] - ETA: 0s - loss: 8.8560 - acc: 0.4292Epoch 00007: val_loss improved from 9.39130 to 9.30536, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.8708 - acc: 0.4283 - val_loss: 9.3054 - val_acc: 0.3533
Epoch 9/20
6620/6680 [============================&gt;.] - ETA: 0s - loss: 8.6734 - acc: 0.4458Epoch 00008: val_loss improved from 9.30536 to 9.11986, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.6751 - acc: 0.4458 - val_loss: 9.1199 - val_acc: 0.3760
Epoch 10/20
6580/6680 [============================&gt;.] - ETA: 0s - loss: 8.5635 - acc: 0.4514Epoch 00009: val_loss improved from 9.11986 to 9.01053, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.5619 - acc: 0.4513 - val_loss: 9.0105 - val_acc: 0.3760
Epoch 11/20
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 8.4851 - acc: 0.4618Epoch 00010: val_loss improved from 9.01053 to 8.95114, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.4876 - acc: 0.4618 - val_loss: 8.9511 - val_acc: 0.3904
Epoch 12/20
6660/6680 [============================&gt;.] - ETA: 0s - loss: 8.4063 - acc: 0.4667Epoch 00011: val_loss improved from 8.95114 to 8.93362, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.4119 - acc: 0.4663 - val_loss: 8.9336 - val_acc: 0.3892
Epoch 13/20
6560/6680 [============================&gt;.] - ETA: 0s - loss: 8.3734 - acc: 0.4700Epoch 00012: val_loss improved from 8.93362 to 8.87343, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.3600 - acc: 0.4707 - val_loss: 8.8734 - val_acc: 0.3940
Epoch 14/20
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 8.2867 - acc: 0.4783Epoch 00013: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 8.2984 - acc: 0.4777 - val_loss: 8.8784 - val_acc: 0.3916
Epoch 15/20
6600/6680 [============================&gt;.] - ETA: 0s - loss: 8.2782 - acc: 0.4818Epoch 00014: val_loss improved from 8.87343 to 8.83293, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.2782 - acc: 0.4817 - val_loss: 8.8329 - val_acc: 0.4024
Epoch 16/20
6580/6680 [============================&gt;.] - ETA: 0s - loss: 8.2628 - acc: 0.4839Epoch 00015: val_loss improved from 8.83293 to 8.82375, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.2695 - acc: 0.4835 - val_loss: 8.8237 - val_acc: 0.4024
Epoch 17/20
6620/6680 [============================&gt;.] - ETA: 0s - loss: 8.2526 - acc: 0.4861Epoch 00016: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 8.2605 - acc: 0.4856 - val_loss: 8.8274 - val_acc: 0.4084
Epoch 18/20
6640/6680 [============================&gt;.] - ETA: 0s - loss: 8.2573 - acc: 0.4822Epoch 00017: val_loss improved from 8.82375 to 8.82262, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.2368 - acc: 0.4835 - val_loss: 8.8226 - val_acc: 0.4000
Epoch 19/20
6640/6680 [============================&gt;.] - ETA: 0s - loss: 8.0738 - acc: 0.4925Epoch 00018: val_loss improved from 8.82262 to 8.67756, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.0783 - acc: 0.4921 - val_loss: 8.6776 - val_acc: 0.4096
Epoch 20/20
6640/6680 [============================&gt;.] - ETA: 0s - loss: 7.9981 - acc: 0.4983Epoch 00019: val_loss improved from 8.67756 to 8.64432, saving model to /output/weights.best.VGG16.hdf5
6680/6680 [==============================] - 1s - loss: 8.0014 - acc: 0.4981 - val_loss: 8.6443 - val_acc: 0.4060
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[24]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x7fad442089e8&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-the-Model-with-the-Best-Validation-Loss">Load the Model with the Best Validation Loss<a class="anchor-link" href="#Load-the-Model-with-the-Best-Validation-Loss">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">VGG16_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;/output/weights.best.VGG16.hdf5&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Test-the-Model">Test the Model<a class="anchor-link" href="#Test-the-Model">&#182;</a></h3><p>Now, we can use the CNN to test how well it identifies breed within our test dataset of dog images.  We print the test accuracy below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get index of predicted dog breed for each image in test set</span>
<span class="n">VGG16_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">VGG16_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">test_VGG16</span><span class="p">]</span>

<span class="c1"># report test accuracy</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">VGG16_predictions</span><span class="p">)</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_targets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">VGG16_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: </span><span class="si">%.4f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">test_accuracy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test accuracy: 41.0287%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Predict-Dog-Breed-with-the-Model">Predict Dog Breed with the Model<a class="anchor-link" href="#Predict-Dog-Breed-with-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">extract_bottleneck_features</span> <span class="k">import</span> <span class="o">*</span>

<span class="k">def</span> <span class="nf">VGG16_predict_breed</span><span class="p">(</span><span class="n">img_path</span><span class="p">):</span>
    <span class="c1"># extract bottleneck features</span>
    <span class="n">bottleneck_feature</span> <span class="o">=</span> <span class="n">extract_VGG16</span><span class="p">(</span><span class="n">path_to_tensor</span><span class="p">(</span><span class="n">img_path</span><span class="p">))</span>
    <span class="c1"># obtain predicted vector</span>
    <span class="n">predicted_vector</span> <span class="o">=</span> <span class="n">VGG16_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">bottleneck_feature</span><span class="p">)</span>
    <span class="c1"># return dog breed that is predicted by the model</span>
    <span class="k">return</span> <span class="n">dog_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predicted_vector</span><span class="p">)]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step5'></a></p>
<h2 id="Step-5:-Create-a-CNN-to-Classify-Dog-Breeds-(using-Transfer-Learning)">Step 5: Create a CNN to Classify Dog Breeds (using Transfer Learning)<a class="anchor-link" href="#Step-5:-Create-a-CNN-to-Classify-Dog-Breeds-(using-Transfer-Learning)">&#182;</a></h2><p>You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.</p>
<p>In Step 4, we used transfer learning to create a CNN using VGG-16 bottleneck features.  In this section, you must use the bottleneck features from a different pre-trained model.  To make things easier for you, we have pre-computed the features for all of the networks that are currently available in Keras:</p>
<ul>
<li><a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogVGG19Data.npz">VGG-19</a> bottleneck features</li>
<li><a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz">ResNet-50</a> bottleneck features</li>
<li><a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogInceptionV3Data.npz">Inception</a> bottleneck features</li>
<li><a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogXceptionData.npz">Xception</a> bottleneck features</li>
</ul>
<p>The files are encoded as such:</p>

<pre><code>Dog{network}Data.npz

</code></pre>
<p>where <code>{network}</code>, in the above filename, can be one of <code>VGG19</code>, <code>Resnet50</code>, <code>InceptionV3</code>, or <code>Xception</code>.  Pick one of the above architectures, download the corresponding bottleneck features, and store the downloaded file in the <code>bottleneck_features/</code> folder in the repository.</p>
<h3 id="(IMPLEMENTATION)-Obtain-Bottleneck-Features">(IMPLEMENTATION) Obtain Bottleneck Features<a class="anchor-link" href="#(IMPLEMENTATION)-Obtain-Bottleneck-Features">&#182;</a></h3><p>In the code block below, extract the bottleneck features corresponding to the train, test, and validation sets by running the following:</p>

<pre><code>bottleneck_features = np.load('bottleneck_features/Dog{network}Data.npz')
train_{network} = bottleneck_features['train']
valid_{network} = bottleneck_features['valid']
test_{network} = bottleneck_features['test']</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Obtain bottleneck features from another pre-trained CNN.</span>
<span class="n">bottleneck_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/bottleneck_features/DogVGG19Data.npz&#39;</span><span class="p">)</span>
<span class="n">train_VGG19</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
<span class="n">valid_VGG19</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">]</span>
<span class="n">test_VGG19</span> <span class="o">=</span> <span class="n">bottleneck_features</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Model-Architecture">(IMPLEMENTATION) Model Architecture<a class="anchor-link" href="#(IMPLEMENTATION)-Model-Architecture">&#182;</a></h3><p>Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:</p>

<pre><code>    &lt;your model's name&gt;.summary()

</code></pre>
<p><strong>Question 5:</strong> Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem.</p>
<p><strong>Answer:</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[180]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Define your architecture.</span>
<span class="n">VGG19_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_VGG19</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_VGG19</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="c1">#VGG19_model.add(Dense(1000, activation =&#39;relu&#39;,input_shape=train_VGG19.shape[1:]))</span>
<span class="c1">#VGG19_model.add(Conv2D(128, kernel_size=(2, 2),strides=(1, 1), activation=&#39;relu&#39;, input_shape=train_VGG19.shape[1:]))</span>
<span class="c1">#VGG19_model.add(MaxPooling2D(pool_size=(2, 2)))</span>
<span class="c1">#VGG19_model.add(Dropout(0.3))</span>
<span class="c1">#VGG19_model.add(Conv2D(256, (2,2),activation=&#39;relu&#39;))</span>
<span class="c1">#VGG19_model.add(Conv2D(128, kernel_size=(2,2),activation=&#39;relu&#39;))</span>
<span class="c1">#VGG19_model.add(MaxPooling2D(pool_size=(2, 2)))</span>
<span class="c1">#VGG19_model.add(Dropout(0.5))</span>
<span class="c1">#VGG19_model.add(Conv2D(512, kernel_size=(2,2),activation=&#39;relu&#39;))</span>
<span class="c1">#VGG19_model.add(MaxPooling2D(pool_size=(2, 2)))</span>
<span class="c1">#VGG19_model.add(Dropout(0.5))</span>
<span class="c1">#VGG19_model.add(Conv2D(1024, kernel_size=(2,2),activation=&#39;relu&#39;))</span>
<span class="c1">#VGG19_model.add(Dropout(0.2))</span>
<span class="c1">#VGG19_model.add(GlobalAveragePooling2D())</span>
<span class="c1">#VGG19_model.add(GlobalAveragePooling2D(input_shape=train_VGG19.shape[1:]))</span>
<span class="c1">#VGG19_model.add(Dense(1000, activation =&#39;tanh&#39;))</span>
<span class="c1">#VGG19_model.add(Dropout(0.3))</span>

<span class="c1">#VGG19_model.add(Dropout(0.2))</span>

<span class="n">VGG19_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">train_VGG19</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">VGG19_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">133</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">VGG19_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(6680, 7, 7, 512)
(7, 7, 512)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d_25  (None, 512)               0         
_________________________________________________________________
dense_27 (Dense)             (None, 133)               68229     
=================================================================
Total params: 68,229
Trainable params: 68,229
Non-trainable params: 0
_________________________________________________________________
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Compile-the-Model">(IMPLEMENTATION) Compile the Model<a class="anchor-link" href="#(IMPLEMENTATION)-Compile-the-Model">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[182]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Compile the model.</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">optimizers</span>
<span class="n">VGG19_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="c1">#VGG19_model.compile(loss=&#39;binary_crossentropy&#39;, optimizer = optimizers.SGD(lr=1e-4, momentum=0.9),metrics=[&#39;accuracy&#39;])</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Train-the-Model">(IMPLEMENTATION) Train the Model<a class="anchor-link" href="#(IMPLEMENTATION)-Train-the-Model">&#182;</a></h3><p>Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.</p>
<p>You are welcome to <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html">augment the training data</a>, but this is not a requirement.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[183]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Train the model.</span>
<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;/output/weights_15.best.VGG19.hdf5&#39;</span><span class="p">,</span> 
                               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">VGG19_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_VGG19</span><span class="p">,</span> <span class="n">train_targets</span><span class="p">,</span> 
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_VGG19</span><span class="p">,</span> <span class="n">valid_targets</span><span class="p">),</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 6680 samples, validate on 835 samples
Epoch 1/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 12.5930 - acc: 0.1132Epoch 00000: val_loss improved from inf to 11.21307, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 3s - loss: 12.5476 - acc: 0.1154 - val_loss: 11.2131 - val_acc: 0.1749
Epoch 2/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 10.3191 - acc: 0.2607Epoch 00001: val_loss improved from 11.21307 to 10.13877, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 10.2974 - acc: 0.2621 - val_loss: 10.1388 - val_acc: 0.2671
Epoch 3/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 9.7217 - acc: 0.3363Epoch 00002: val_loss improved from 10.13877 to 9.97177, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 9.7220 - acc: 0.3362 - val_loss: 9.9718 - val_acc: 0.2934
Epoch 4/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 9.5194 - acc: 0.3673Epoch 00003: val_loss improved from 9.97177 to 9.77055, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 9.5094 - acc: 0.3680 - val_loss: 9.7706 - val_acc: 0.3222
Epoch 5/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 9.3357 - acc: 0.3880Epoch 00004: val_loss improved from 9.77055 to 9.62755, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 9.3419 - acc: 0.3882 - val_loss: 9.6276 - val_acc: 0.3377
Epoch 6/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 9.2151 - acc: 0.4055Epoch 00005: val_loss improved from 9.62755 to 9.56371, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 9.1989 - acc: 0.4069 - val_loss: 9.5637 - val_acc: 0.3377
Epoch 7/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 9.1414 - acc: 0.4166Epoch 00006: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 9.1503 - acc: 0.4162 - val_loss: 9.5711 - val_acc: 0.3425
Epoch 8/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 9.1149 - acc: 0.4210Epoch 00007: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 9.1234 - acc: 0.4205 - val_loss: 9.6004 - val_acc: 0.3461
Epoch 9/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 9.0377 - acc: 0.4261Epoch 00008: val_loss improved from 9.56371 to 9.39461, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 9.0408 - acc: 0.4257 - val_loss: 9.3946 - val_acc: 0.3617
Epoch 10/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 8.9737 - acc: 0.4356Epoch 00009: val_loss improved from 9.39461 to 9.36780, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.9758 - acc: 0.4355 - val_loss: 9.3678 - val_acc: 0.3677
Epoch 11/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 8.8841 - acc: 0.4375Epoch 00010: val_loss improved from 9.36780 to 9.22282, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.8797 - acc: 0.4380 - val_loss: 9.2228 - val_acc: 0.3581
Epoch 12/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 8.6172 - acc: 0.4486Epoch 00011: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 8.6122 - acc: 0.4487 - val_loss: 9.2511 - val_acc: 0.3557
Epoch 13/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 8.5258 - acc: 0.4619Epoch 00012: val_loss improved from 9.22282 to 9.12028, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.5424 - acc: 0.4609 - val_loss: 9.1203 - val_acc: 0.3665
Epoch 14/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 8.4738 - acc: 0.4654Epoch 00013: val_loss improved from 9.12028 to 8.98278, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.4627 - acc: 0.4660 - val_loss: 8.9828 - val_acc: 0.3772
Epoch 15/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 8.3673 - acc: 0.4739Epoch 00014: val_loss improved from 8.98278 to 8.91438, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.3712 - acc: 0.4737 - val_loss: 8.9144 - val_acc: 0.3916
Epoch 16/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 8.3219 - acc: 0.4743Epoch 00015: val_loss improved from 8.91438 to 8.85697, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.3163 - acc: 0.4747 - val_loss: 8.8570 - val_acc: 0.3880
Epoch 17/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 8.1970 - acc: 0.4804Epoch 00016: val_loss improved from 8.85697 to 8.75287, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.1885 - acc: 0.4811 - val_loss: 8.7529 - val_acc: 0.4072
Epoch 18/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 8.0992 - acc: 0.4857Epoch 00017: val_loss improved from 8.75287 to 8.61176, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 8.1015 - acc: 0.4856 - val_loss: 8.6118 - val_acc: 0.3988
Epoch 19/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 7.9908 - acc: 0.4928Epoch 00018: val_loss improved from 8.61176 to 8.57340, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.9646 - acc: 0.4943 - val_loss: 8.5734 - val_acc: 0.4012
Epoch 20/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 7.9252 - acc: 0.5005Epoch 00019: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.9249 - acc: 0.5007 - val_loss: 8.5752 - val_acc: 0.4084
Epoch 21/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 7.9054 - acc: 0.5035Epoch 00020: val_loss improved from 8.57340 to 8.52662, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.9101 - acc: 0.5031 - val_loss: 8.5266 - val_acc: 0.4060
Epoch 22/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 7.7940 - acc: 0.5086Epoch 00021: val_loss improved from 8.52662 to 8.45777, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.7972 - acc: 0.5084 - val_loss: 8.4578 - val_acc: 0.4132
Epoch 23/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 7.7466 - acc: 0.5156Epoch 00022: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.7586 - acc: 0.5147 - val_loss: 8.5217 - val_acc: 0.4072
Epoch 24/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 7.7428 - acc: 0.5181Epoch 00023: val_loss improved from 8.45777 to 8.38424, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.7507 - acc: 0.5174 - val_loss: 8.3842 - val_acc: 0.4132
Epoch 25/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 7.7676 - acc: 0.5164Epoch 00024: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.7429 - acc: 0.5180 - val_loss: 8.5073 - val_acc: 0.4144
Epoch 26/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 7.7298 - acc: 0.5172Epoch 00025: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.7295 - acc: 0.5171 - val_loss: 8.4540 - val_acc: 0.4132
Epoch 27/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 7.6778 - acc: 0.5191Epoch 00026: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.7013 - acc: 0.5178 - val_loss: 8.4270 - val_acc: 0.4192
Epoch 28/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 7.6872 - acc: 0.5198Epoch 00027: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.6853 - acc: 0.5198 - val_loss: 8.4255 - val_acc: 0.4132
Epoch 29/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 7.6312 - acc: 0.5213Epoch 00028: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.6141 - acc: 0.5223 - val_loss: 8.3904 - val_acc: 0.4132
Epoch 30/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 7.5384 - acc: 0.5293Epoch 00029: val_loss improved from 8.38424 to 8.29951, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.5372 - acc: 0.5295 - val_loss: 8.2995 - val_acc: 0.4216
Epoch 31/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 7.5273 - acc: 0.5304Epoch 00030: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.5337 - acc: 0.5301 - val_loss: 8.3387 - val_acc: 0.4192
Epoch 32/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 7.5330 - acc: 0.5311Epoch 00031: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 7.5273 - acc: 0.5314 - val_loss: 8.3033 - val_acc: 0.4323
Epoch 33/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 7.4942 - acc: 0.5324Epoch 00032: val_loss improved from 8.29951 to 8.28311, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.5169 - acc: 0.5307 - val_loss: 8.2831 - val_acc: 0.4263
Epoch 34/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 7.4376 - acc: 0.5343Epoch 00033: val_loss improved from 8.28311 to 8.19393, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.4201 - acc: 0.5355 - val_loss: 8.1939 - val_acc: 0.4311
Epoch 35/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 7.3787 - acc: 0.5409Epoch 00034: val_loss improved from 8.19393 to 8.17487, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.3959 - acc: 0.5398 - val_loss: 8.1749 - val_acc: 0.4323
Epoch 36/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 7.3091 - acc: 0.5404Epoch 00035: val_loss improved from 8.17487 to 8.15980, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.3113 - acc: 0.5398 - val_loss: 8.1598 - val_acc: 0.4204
Epoch 37/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 7.0386 - acc: 0.5536Epoch 00036: val_loss improved from 8.15980 to 7.86283, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 7.0392 - acc: 0.5536 - val_loss: 7.8628 - val_acc: 0.4515
Epoch 38/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 6.9798 - acc: 0.5633Epoch 00037: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.9790 - acc: 0.5633 - val_loss: 7.8655 - val_acc: 0.4407
Epoch 39/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.9590 - acc: 0.5619Epoch 00038: val_loss improved from 7.86283 to 7.81287, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.9304 - acc: 0.5635 - val_loss: 7.8129 - val_acc: 0.4455
Epoch 40/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.8993 - acc: 0.5681Epoch 00039: val_loss improved from 7.81287 to 7.70525, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.8788 - acc: 0.5693 - val_loss: 7.7052 - val_acc: 0.4539
Epoch 41/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.8808 - acc: 0.5698Epoch 00040: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.8688 - acc: 0.5704 - val_loss: 7.7456 - val_acc: 0.4563
Epoch 42/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.8498 - acc: 0.5725Epoch 00041: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.8507 - acc: 0.5723 - val_loss: 7.7287 - val_acc: 0.4527
Epoch 43/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.8113 - acc: 0.5732Epoch 00042: val_loss improved from 7.70525 to 7.64989, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.7977 - acc: 0.5738 - val_loss: 7.6499 - val_acc: 0.4659
Epoch 44/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.8011 - acc: 0.5761Epoch 00043: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.7810 - acc: 0.5774 - val_loss: 7.6774 - val_acc: 0.4623
Epoch 45/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.7885 - acc: 0.5775Epoch 00044: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.7761 - acc: 0.5781 - val_loss: 7.6883 - val_acc: 0.4587
Epoch 46/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 6.7594 - acc: 0.5784Epoch 00045: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.7539 - acc: 0.5786 - val_loss: 7.8330 - val_acc: 0.4467
Epoch 47/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.6591 - acc: 0.5812Epoch 00046: val_loss improved from 7.64989 to 7.60067, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.6506 - acc: 0.5817 - val_loss: 7.6007 - val_acc: 0.4743
Epoch 48/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.5502 - acc: 0.5876Epoch 00047: val_loss improved from 7.60067 to 7.51444, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.5485 - acc: 0.5877 - val_loss: 7.5144 - val_acc: 0.4683
Epoch 49/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.5083 - acc: 0.5927Epoch 00048: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.4946 - acc: 0.5934 - val_loss: 7.5611 - val_acc: 0.4599
Epoch 50/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.4818 - acc: 0.5949Epoch 00049: val_loss improved from 7.51444 to 7.47522, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.4816 - acc: 0.5949 - val_loss: 7.4752 - val_acc: 0.4695
Epoch 51/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.4830 - acc: 0.5958Epoch 00050: val_loss improved from 7.47522 to 7.45021, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.4700 - acc: 0.5967 - val_loss: 7.4502 - val_acc: 0.4671
Epoch 52/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.4357 - acc: 0.5994Epoch 00051: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.4625 - acc: 0.5978 - val_loss: 7.5594 - val_acc: 0.4647
Epoch 53/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 6.4513 - acc: 0.5986Epoch 00052: val_loss improved from 7.45021 to 7.41153, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.4585 - acc: 0.5982 - val_loss: 7.4115 - val_acc: 0.4707
Epoch 54/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 6.4619 - acc: 0.5986Epoch 00053: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.4570 - acc: 0.5990 - val_loss: 7.4433 - val_acc: 0.4814
Epoch 55/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.4734 - acc: 0.5977Epoch 00054: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.4505 - acc: 0.5991 - val_loss: 7.4984 - val_acc: 0.4599
Epoch 56/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.3835 - acc: 0.5989Epoch 00055: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.3710 - acc: 0.5996 - val_loss: 7.5158 - val_acc: 0.4647
Epoch 57/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.2531 - acc: 0.6035Epoch 00056: val_loss improved from 7.41153 to 7.35171, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.2532 - acc: 0.6036 - val_loss: 7.3517 - val_acc: 0.4778
Epoch 58/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.1563 - acc: 0.6115Epoch 00057: val_loss improved from 7.35171 to 7.26150, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.1746 - acc: 0.6103 - val_loss: 7.2615 - val_acc: 0.4778
Epoch 59/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.1397 - acc: 0.6155Epoch 00058: val_loss improved from 7.26150 to 7.18790, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.1552 - acc: 0.6147 - val_loss: 7.1879 - val_acc: 0.4922
Epoch 60/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 6.1525 - acc: 0.6162Epoch 00059: val_loss improved from 7.18790 to 7.18331, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.1403 - acc: 0.6169 - val_loss: 7.1833 - val_acc: 0.4874
Epoch 61/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.1166 - acc: 0.6190Epoch 00060: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1300 - acc: 0.6181 - val_loss: 7.2444 - val_acc: 0.4874
Epoch 62/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 6.1363 - acc: 0.6180Epoch 00061: val_loss improved from 7.18331 to 7.18027, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.1246 - acc: 0.6187 - val_loss: 7.1803 - val_acc: 0.4862
Epoch 63/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.1193 - acc: 0.6200Epoch 00062: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1207 - acc: 0.6198 - val_loss: 7.2370 - val_acc: 0.4826
Epoch 64/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.1217 - acc: 0.6195Epoch 00063: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1199 - acc: 0.6195 - val_loss: 7.2088 - val_acc: 0.4790
Epoch 65/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.1014 - acc: 0.6213Epoch 00064: val_loss improved from 7.18027 to 7.12601, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 6.1207 - acc: 0.6201 - val_loss: 7.1260 - val_acc: 0.4934
Epoch 66/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.1187 - acc: 0.6201Epoch 00065: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1198 - acc: 0.6201 - val_loss: 7.1908 - val_acc: 0.4862
Epoch 67/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.1432 - acc: 0.6188Epoch 00066: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1182 - acc: 0.6204 - val_loss: 7.1739 - val_acc: 0.4946
Epoch 68/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.0836 - acc: 0.6223Epoch 00067: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1194 - acc: 0.6201 - val_loss: 7.1895 - val_acc: 0.4910
Epoch 69/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.1030 - acc: 0.6211Epoch 00068: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1181 - acc: 0.6202 - val_loss: 7.1599 - val_acc: 0.4898
Epoch 70/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.1094 - acc: 0.6208Epoch 00069: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1187 - acc: 0.6202 - val_loss: 7.1774 - val_acc: 0.4946
Epoch 71/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.1230 - acc: 0.6200Epoch 00070: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1177 - acc: 0.6204 - val_loss: 7.1684 - val_acc: 0.4874
Epoch 72/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.0951 - acc: 0.6218Epoch 00071: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1186 - acc: 0.6204 - val_loss: 7.1659 - val_acc: 0.4898
Epoch 73/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 6.0997 - acc: 0.6213Epoch 00072: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1174 - acc: 0.6202 - val_loss: 7.2787 - val_acc: 0.4874
Epoch 74/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.1137 - acc: 0.6200Epoch 00073: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1159 - acc: 0.6199 - val_loss: 7.1981 - val_acc: 0.4934
Epoch 75/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.1073 - acc: 0.6209Epoch 00074: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1154 - acc: 0.6204 - val_loss: 7.2026 - val_acc: 0.4922
Epoch 76/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 6.1229 - acc: 0.6198Epoch 00075: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1147 - acc: 0.6204 - val_loss: 7.2401 - val_acc: 0.4838
Epoch 77/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.1095 - acc: 0.6206Epoch 00076: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1139 - acc: 0.6204 - val_loss: 7.2241 - val_acc: 0.4922
Epoch 78/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 6.1098 - acc: 0.6208Epoch 00077: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1139 - acc: 0.6205 - val_loss: 7.1701 - val_acc: 0.4946
Epoch 79/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.1436 - acc: 0.6186Epoch 00078: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1127 - acc: 0.6205 - val_loss: 7.1727 - val_acc: 0.4958
Epoch 80/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.1152 - acc: 0.6203Epoch 00079: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.1099 - acc: 0.6205 - val_loss: 7.2941 - val_acc: 0.4838
Epoch 81/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 6.0838 - acc: 0.6204Epoch 00080: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0905 - acc: 0.6199 - val_loss: 7.3059 - val_acc: 0.4826
Epoch 82/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 6.0366 - acc: 0.6225Epoch 00081: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0573 - acc: 0.6211 - val_loss: 7.2248 - val_acc: 0.4886
Epoch 83/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.0359 - acc: 0.6241Epoch 00082: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0416 - acc: 0.6238 - val_loss: 7.2413 - val_acc: 0.4910
Epoch 84/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.0360 - acc: 0.6237Epoch 00083: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0357 - acc: 0.6238 - val_loss: 7.1994 - val_acc: 0.4946
Epoch 85/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.0899 - acc: 0.6202Epoch 00084: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0322 - acc: 0.6238 - val_loss: 7.1782 - val_acc: 0.4850
Epoch 86/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.0300 - acc: 0.6250Epoch 00085: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0250 - acc: 0.6253 - val_loss: 7.1822 - val_acc: 0.4946
Epoch 87/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 6.0246 - acc: 0.6254Epoch 00086: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0204 - acc: 0.6256 - val_loss: 7.2226 - val_acc: 0.4838
Epoch 88/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 6.0383 - acc: 0.6244Epoch 00087: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 6.0194 - acc: 0.6256 - val_loss: 7.2449 - val_acc: 0.4826
Epoch 89/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.9447 - acc: 0.6258Epoch 00088: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.9574 - acc: 0.6251 - val_loss: 7.1710 - val_acc: 0.4850
Epoch 90/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.8065 - acc: 0.6333Epoch 00089: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.8180 - acc: 0.6326 - val_loss: 7.1554 - val_acc: 0.4874
Epoch 91/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.7634 - acc: 0.6379Epoch 00090: val_loss improved from 7.12601 to 7.00850, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 5.7681 - acc: 0.6376 - val_loss: 7.0085 - val_acc: 0.4946
Epoch 92/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.7392 - acc: 0.6417Epoch 00091: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.7545 - acc: 0.6407 - val_loss: 7.0288 - val_acc: 0.4886
Epoch 93/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.7563 - acc: 0.6411Epoch 00092: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.7492 - acc: 0.6416 - val_loss: 7.0941 - val_acc: 0.4910
Epoch 94/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.7509 - acc: 0.6415Epoch 00093: val_loss improved from 7.00850 to 6.99826, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 5.7453 - acc: 0.6419 - val_loss: 6.9983 - val_acc: 0.5018
Epoch 95/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.7456 - acc: 0.6421Epoch 00094: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.7377 - acc: 0.6425 - val_loss: 7.0459 - val_acc: 0.4934
Epoch 96/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6821 - acc: 0.6435Epoch 00095: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6679 - acc: 0.6443 - val_loss: 7.0512 - val_acc: 0.4970
Epoch 97/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6450 - acc: 0.6466Epoch 00096: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6329 - acc: 0.6475 - val_loss: 7.0537 - val_acc: 0.4958
Epoch 98/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6473 - acc: 0.6481Epoch 00097: val_loss improved from 6.99826 to 6.97474, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 5.6254 - acc: 0.6496 - val_loss: 6.9747 - val_acc: 0.5030
Epoch 99/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6012 - acc: 0.6509Epoch 00098: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6159 - acc: 0.6500 - val_loss: 6.9993 - val_acc: 0.5054
Epoch 100/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6323 - acc: 0.6492Epoch 00099: val_loss improved from 6.97474 to 6.97137, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 5.6168 - acc: 0.6501 - val_loss: 6.9714 - val_acc: 0.5018
Epoch 101/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6083 - acc: 0.6512Epoch 00100: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6128 - acc: 0.6509 - val_loss: 6.9799 - val_acc: 0.5006
Epoch 102/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6102 - acc: 0.6507Epoch 00101: val_loss improved from 6.97137 to 6.92989, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 5.6098 - acc: 0.6507 - val_loss: 6.9299 - val_acc: 0.5078
Epoch 103/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5813 - acc: 0.6526Epoch 00102: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6102 - acc: 0.6509 - val_loss: 6.9547 - val_acc: 0.4970
Epoch 104/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6106 - acc: 0.6515Epoch 00103: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6080 - acc: 0.6516 - val_loss: 6.9786 - val_acc: 0.5066
Epoch 105/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6004 - acc: 0.6520Epoch 00104: val_loss improved from 6.92989 to 6.91805, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 5.6085 - acc: 0.6515 - val_loss: 6.9180 - val_acc: 0.5078
Epoch 106/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6158 - acc: 0.6513Epoch 00105: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6082 - acc: 0.6518 - val_loss: 6.9622 - val_acc: 0.4994
Epoch 107/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6105 - acc: 0.6514Epoch 00106: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6082 - acc: 0.6515 - val_loss: 6.9486 - val_acc: 0.5018
Epoch 108/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6111 - acc: 0.6515Epoch 00107: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6518 - val_loss: 6.9605 - val_acc: 0.5054
Epoch 109/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6061 - acc: 0.6520Epoch 00108: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9575 - val_acc: 0.5006
Epoch 110/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6178 - acc: 0.6515Epoch 00109: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6054 - acc: 0.6522 - val_loss: 6.9473 - val_acc: 0.5006
Epoch 111/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6187 - acc: 0.6511Epoch 00110: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6075 - acc: 0.6518 - val_loss: 6.9315 - val_acc: 0.5078
Epoch 112/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6333 - acc: 0.6503Epoch 00111: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9287 - val_acc: 0.4982
Epoch 113/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6199 - acc: 0.6509Epoch 00112: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6060 - acc: 0.6518 - val_loss: 6.9199 - val_acc: 0.5030
Epoch 114/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6165 - acc: 0.6515Epoch 00113: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6063 - acc: 0.6521 - val_loss: 6.9546 - val_acc: 0.5042
Epoch 115/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6113 - acc: 0.6517Epoch 00114: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9186 - val_acc: 0.5090
Epoch 116/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6166 - acc: 0.6514Epoch 00115: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9360 - val_acc: 0.5066
Epoch 117/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6047 - acc: 0.6522Epoch 00116: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6058 - acc: 0.6521 - val_loss: 6.9569 - val_acc: 0.5042
Epoch 118/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6051 - acc: 0.6522Epoch 00117: val_loss improved from 6.91805 to 6.91700, saving model to /output/weights_15.best.VGG19.hdf5
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9170 - val_acc: 0.5054
Epoch 119/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5988 - acc: 0.6526Epoch 00118: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9445 - val_acc: 0.5042
Epoch 120/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6045 - acc: 0.6521Epoch 00119: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9304 - val_acc: 0.5054
Epoch 121/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6113 - acc: 0.6518Epoch 00120: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9877 - val_acc: 0.5030
Epoch 122/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6043 - acc: 0.6521Epoch 00121: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9538 - val_acc: 0.4994
Epoch 123/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6246 - acc: 0.6509Epoch 00122: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9373 - val_acc: 0.5030
Epoch 124/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5818 - acc: 0.6536Epoch 00123: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6062 - acc: 0.6521 - val_loss: 6.9503 - val_acc: 0.4970
Epoch 125/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5780 - acc: 0.6538Epoch 00124: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6055 - acc: 0.6521 - val_loss: 6.9354 - val_acc: 0.5042
Epoch 126/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6086 - acc: 0.6518Epoch 00125: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6063 - acc: 0.6519 - val_loss: 6.9843 - val_acc: 0.5054
Epoch 127/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6084 - acc: 0.6519Epoch 00126: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9298 - val_acc: 0.5090
Epoch 128/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6021 - acc: 0.6523Epoch 00127: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6060 - acc: 0.6521 - val_loss: 6.9453 - val_acc: 0.5078
Epoch 129/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5975 - acc: 0.6525Epoch 00128: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9374 - val_acc: 0.5126
Epoch 130/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5933 - acc: 0.6528Epoch 00129: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6519 - val_loss: 6.9438 - val_acc: 0.5078
Epoch 131/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6271 - acc: 0.6507Epoch 00130: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9309 - val_acc: 0.5066
Epoch 132/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5999 - acc: 0.6524Epoch 00131: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9375 - val_acc: 0.5066
Epoch 133/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5881 - acc: 0.6531Epoch 00132: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9401 - val_acc: 0.5030
Epoch 134/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6519Epoch 00133: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9421 - val_acc: 0.5030
Epoch 135/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6422 - acc: 0.6499Epoch 00134: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9317 - val_acc: 0.4994
Epoch 136/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5672 - acc: 0.6546Epoch 00135: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9348 - val_acc: 0.5042
Epoch 137/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5722 - acc: 0.6543Epoch 00136: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9296 - val_acc: 0.5054
Epoch 138/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6071 - acc: 0.6519Epoch 00137: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9360 - val_acc: 0.5066
Epoch 139/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6352 - acc: 0.6504Epoch 00138: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6054 - acc: 0.6521 - val_loss: 6.9736 - val_acc: 0.5054
Epoch 140/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6052 - acc: 0.6522Epoch 00139: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6063 - acc: 0.6521 - val_loss: 6.9429 - val_acc: 0.5054
Epoch 141/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6226 - acc: 0.6512Epoch 00140: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6076 - acc: 0.6521 - val_loss: 6.9508 - val_acc: 0.5042
Epoch 142/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6140 - acc: 0.6517Epoch 00141: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9566 - val_acc: 0.5042
Epoch 143/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6226 - acc: 0.6512Epoch 00142: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9503 - val_acc: 0.5030
Epoch 144/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6329 - acc: 0.6503Epoch 00143: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6519 - val_loss: 6.9381 - val_acc: 0.5066
Epoch 145/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6172 - acc: 0.6513Epoch 00144: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9490 - val_acc: 0.5102
Epoch 146/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5891 - acc: 0.6531Epoch 00145: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9434 - val_acc: 0.5078
Epoch 147/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6209 - acc: 0.6511Epoch 00146: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9424 - val_acc: 0.5066
Epoch 148/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6290 - acc: 0.6508Epoch 00147: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9413 - val_acc: 0.5042
Epoch 149/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5836 - acc: 0.6534Epoch 00148: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9483 - val_acc: 0.5042
Epoch 150/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6518Epoch 00149: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9414 - val_acc: 0.5042
Epoch 151/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6023 - acc: 0.6524Epoch 00150: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9392 - val_acc: 0.5006
Epoch 152/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.5972 - acc: 0.6526Epoch 00151: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9394 - val_acc: 0.5006
Epoch 153/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5955 - acc: 0.6526Epoch 00152: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6519 - val_loss: 6.9502 - val_acc: 0.5030
Epoch 154/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6066 - acc: 0.6521Epoch 00153: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6063 - acc: 0.6521 - val_loss: 6.9574 - val_acc: 0.5042
Epoch 155/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5993 - acc: 0.6524Epoch 00154: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9469 - val_acc: 0.5018
Epoch 156/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5908 - acc: 0.6530Epoch 00155: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6059 - acc: 0.6521 - val_loss: 6.9480 - val_acc: 0.5042
Epoch 157/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5895 - acc: 0.6530Epoch 00156: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9485 - val_acc: 0.5042
Epoch 158/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5999 - acc: 0.6525Epoch 00157: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9357 - val_acc: 0.5030
Epoch 159/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6151 - acc: 0.6514Epoch 00158: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6519 - val_loss: 6.9358 - val_acc: 0.5042
Epoch 160/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5921 - acc: 0.6530Epoch 00159: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6062 - acc: 0.6521 - val_loss: 6.9794 - val_acc: 0.5078
Epoch 161/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6518Epoch 00160: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9603 - val_acc: 0.5054
Epoch 162/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6077 - acc: 0.6520Epoch 00161: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6063 - acc: 0.6521 - val_loss: 6.9529 - val_acc: 0.4994
Epoch 163/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6186 - acc: 0.6512Epoch 00162: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9499 - val_acc: 0.5018
Epoch 164/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5981 - acc: 0.6526Epoch 00163: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9491 - val_acc: 0.5018
Epoch 165/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6118 - acc: 0.6517Epoch 00164: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9606 - val_acc: 0.4994
Epoch 166/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6383 - acc: 0.6500Epoch 00165: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9637 - val_acc: 0.5030
Epoch 167/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5930 - acc: 0.6528Epoch 00166: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9681 - val_acc: 0.5042
Epoch 168/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5859 - acc: 0.6533Epoch 00167: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6054 - acc: 0.6521 - val_loss: 6.9992 - val_acc: 0.4970
Epoch 169/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6039 - acc: 0.6521Epoch 00168: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9577 - val_acc: 0.5018
Epoch 170/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6007 - acc: 0.6523Epoch 00169: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9471 - val_acc: 0.5042
Epoch 171/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5983 - acc: 0.6526Epoch 00170: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9596 - val_acc: 0.5054
Epoch 172/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6093 - acc: 0.6518Epoch 00171: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9491 - val_acc: 0.5042
Epoch 173/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.5991 - acc: 0.6526Epoch 00172: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6064 - acc: 0.6521 - val_loss: 6.9574 - val_acc: 0.5078
Epoch 174/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5891 - acc: 0.6531Epoch 00173: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9555 - val_acc: 0.5042
Epoch 175/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6040 - acc: 0.6523Epoch 00174: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6065 - acc: 0.6521 - val_loss: 6.9474 - val_acc: 0.5066
Epoch 176/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6082 - acc: 0.6519Epoch 00175: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9443 - val_acc: 0.5042
Epoch 177/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6140 - acc: 0.6517Epoch 00176: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6057 - acc: 0.6521 - val_loss: 6.9859 - val_acc: 0.5066
Epoch 178/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5946 - acc: 0.6527Epoch 00177: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9497 - val_acc: 0.5042
Epoch 179/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5977 - acc: 0.6526Epoch 00178: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6062 - acc: 0.6521 - val_loss: 6.9435 - val_acc: 0.5066
Epoch 180/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6088 - acc: 0.6518Epoch 00179: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9451 - val_acc: 0.5054
Epoch 181/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6118 - acc: 0.6517Epoch 00180: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9392 - val_acc: 0.5042
Epoch 182/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6006 - acc: 0.6523Epoch 00181: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9385 - val_acc: 0.5042
Epoch 183/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5824 - acc: 0.6536Epoch 00182: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9430 - val_acc: 0.5042
Epoch 184/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5951 - acc: 0.6528Epoch 00183: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6065 - acc: 0.6521 - val_loss: 6.9680 - val_acc: 0.5042
Epoch 185/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6305 - acc: 0.6505Epoch 00184: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9471 - val_acc: 0.5030
Epoch 186/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5658 - acc: 0.6546Epoch 00185: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9387 - val_acc: 0.5030
Epoch 187/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6071 - acc: 0.6519Epoch 00186: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9318 - val_acc: 0.5030
Epoch 188/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5954 - acc: 0.6527Epoch 00187: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9383 - val_acc: 0.5030
Epoch 189/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5969 - acc: 0.6526Epoch 00188: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9383 - val_acc: 0.5030
Epoch 190/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5950 - acc: 0.6527Epoch 00189: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9477 - val_acc: 0.5042
Epoch 191/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6158 - acc: 0.6514Epoch 00190: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6519 - val_loss: 6.9591 - val_acc: 0.5042
Epoch 192/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6062 - acc: 0.6521Epoch 00191: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6059 - acc: 0.6521 - val_loss: 6.9570 - val_acc: 0.5018
Epoch 193/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5975 - acc: 0.6527Epoch 00192: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6521 - val_loss: 6.9523 - val_acc: 0.5006
Epoch 194/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6119 - acc: 0.6518Epoch 00193: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9551 - val_acc: 0.5018
Epoch 195/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6185 - acc: 0.6512Epoch 00194: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9426 - val_acc: 0.5042
Epoch 196/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6179 - acc: 0.6514Epoch 00195: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9501 - val_acc: 0.5042
Epoch 197/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6263 - acc: 0.6509Epoch 00196: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9543 - val_acc: 0.5054
Epoch 198/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6127 - acc: 0.6518Epoch 00197: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9517 - val_acc: 0.5042
Epoch 199/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5990 - acc: 0.6524Epoch 00198: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9383 - val_acc: 0.5042
Epoch 200/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6259 - acc: 0.6508Epoch 00199: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9418 - val_acc: 0.5054
Epoch 201/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5901 - acc: 0.6530Epoch 00200: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9380 - val_acc: 0.5066
Epoch 202/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5935 - acc: 0.6529Epoch 00201: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9322 - val_acc: 0.5090
Epoch 203/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6333 - acc: 0.6505Epoch 00202: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9394 - val_acc: 0.5078
Epoch 204/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6091 - acc: 0.6519Epoch 00203: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9506 - val_acc: 0.5042
Epoch 205/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5967 - acc: 0.6526Epoch 00204: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9464 - val_acc: 0.5030
Epoch 206/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6445 - acc: 0.6496Epoch 00205: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9527 - val_acc: 0.5042
Epoch 207/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6199 - acc: 0.6513Epoch 00206: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9497 - val_acc: 0.5018
Epoch 208/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6170 - acc: 0.6515Epoch 00207: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9582 - val_acc: 0.5018
Epoch 209/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5876 - acc: 0.6531Epoch 00208: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9734 - val_acc: 0.5054
Epoch 210/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5911 - acc: 0.6531Epoch 00209: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9481 - val_acc: 0.5006
Epoch 211/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6185 - acc: 0.6514Epoch 00210: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9566 - val_acc: 0.5030
Epoch 212/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6135 - acc: 0.6515Epoch 00211: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9659 - val_acc: 0.5030
Epoch 213/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6074 - acc: 0.6519Epoch 00212: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9704 - val_acc: 0.5030
Epoch 214/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.5998 - acc: 0.6526Epoch 00213: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9555 - val_acc: 0.5006
Epoch 215/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5817 - acc: 0.6535Epoch 00214: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9576 - val_acc: 0.5018
Epoch 216/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6309 - acc: 0.6505Epoch 00215: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9537 - val_acc: 0.5018
Epoch 217/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6135 - acc: 0.6517Epoch 00216: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9735 - val_acc: 0.5030
Epoch 218/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6056 - acc: 0.6520Epoch 00217: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9550 - val_acc: 0.5042
Epoch 219/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5881 - acc: 0.6531Epoch 00218: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9614 - val_acc: 0.5042
Epoch 220/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6057 - acc: 0.6522Epoch 00219: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9616 - val_acc: 0.5030
Epoch 221/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6172 - acc: 0.6515Epoch 00220: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9640 - val_acc: 0.5030
Epoch 222/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5712 - acc: 0.6543Epoch 00221: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9647 - val_acc: 0.5030
Epoch 223/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5956 - acc: 0.6528Epoch 00222: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6066 - acc: 0.6521 - val_loss: 6.9581 - val_acc: 0.5042
Epoch 224/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5989 - acc: 0.6526Epoch 00223: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9538 - val_acc: 0.5030
Epoch 225/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6296 - acc: 0.6505Epoch 00224: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9486 - val_acc: 0.5042
Epoch 226/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6112 - acc: 0.6518Epoch 00225: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9357 - val_acc: 0.5042
Epoch 227/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6187 - acc: 0.6512Epoch 00226: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9420 - val_acc: 0.5042
Epoch 228/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6158 - acc: 0.6514Epoch 00227: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9394 - val_acc: 0.5042
Epoch 229/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6211 - acc: 0.6512Epoch 00228: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9458 - val_acc: 0.5042
Epoch 230/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6034 - acc: 0.6522Epoch 00229: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9388 - val_acc: 0.5030
Epoch 231/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5886 - acc: 0.6531Epoch 00230: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9319 - val_acc: 0.5042
Epoch 232/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6036 - acc: 0.6521Epoch 00231: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6062 - acc: 0.6519 - val_loss: 6.9482 - val_acc: 0.5066
Epoch 233/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6002 - acc: 0.6526Epoch 00232: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6061 - acc: 0.6521 - val_loss: 6.9528 - val_acc: 0.5018
Epoch 234/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6085 - acc: 0.6520Epoch 00233: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6062 - acc: 0.6521 - val_loss: 6.9464 - val_acc: 0.5006
Epoch 235/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6284 - acc: 0.6506Epoch 00234: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9466 - val_acc: 0.5006
Epoch 236/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6095 - acc: 0.6520Epoch 00235: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9475 - val_acc: 0.5018
Epoch 237/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6033 - acc: 0.6523Epoch 00236: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9491 - val_acc: 0.5006
Epoch 238/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5893 - acc: 0.6532Epoch 00237: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9448 - val_acc: 0.5018
Epoch 239/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6142 - acc: 0.6515Epoch 00238: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9387 - val_acc: 0.5030
Epoch 240/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.5975 - acc: 0.6527Epoch 00239: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9450 - val_acc: 0.5030
Epoch 241/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6030 - acc: 0.6524Epoch 00240: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9504 - val_acc: 0.5030
Epoch 242/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5781 - acc: 0.6537Epoch 00241: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9554 - val_acc: 0.5030
Epoch 243/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6057 - acc: 0.6520Epoch 00242: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9536 - val_acc: 0.5042
Epoch 244/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6113 - acc: 0.6518Epoch 00243: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9504 - val_acc: 0.5042
Epoch 245/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6247 - acc: 0.6508Epoch 00244: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9506 - val_acc: 0.5042
Epoch 246/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6409 - acc: 0.6498Epoch 00245: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9511 - val_acc: 0.5042
Epoch 247/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5930 - acc: 0.6528Epoch 00246: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9538 - val_acc: 0.5042
Epoch 248/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6108 - acc: 0.6519Epoch 00247: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9460 - val_acc: 0.5054
Epoch 249/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6396 - acc: 0.6499Epoch 00248: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9496 - val_acc: 0.5054
Epoch 250/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6039 - acc: 0.6523Epoch 00249: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9538 - val_acc: 0.5042
Epoch 251/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5887 - acc: 0.6531Epoch 00250: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9531 - val_acc: 0.5042
Epoch 252/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6176 - acc: 0.6514Epoch 00251: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9515 - val_acc: 0.5042
Epoch 253/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5817 - acc: 0.6537Epoch 00252: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9507 - val_acc: 0.5042
Epoch 254/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6013 - acc: 0.6523Epoch 00253: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6058 - acc: 0.6519 - val_loss: 6.9781 - val_acc: 0.5066
Epoch 255/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6165 - acc: 0.6515Epoch 00254: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6065 - acc: 0.6521 - val_loss: 6.9439 - val_acc: 0.5042
Epoch 256/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5763 - acc: 0.6538Epoch 00255: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6519 - val_loss: 6.9471 - val_acc: 0.5054
Epoch 257/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5891 - acc: 0.6531Epoch 00256: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6061 - acc: 0.6521 - val_loss: 6.9522 - val_acc: 0.5042
Epoch 258/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6010 - acc: 0.6523Epoch 00257: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9505 - val_acc: 0.5030
Epoch 259/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6010 - acc: 0.6524Epoch 00258: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6521 - val_loss: 6.9449 - val_acc: 0.5042
Epoch 260/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6046 - acc: 0.6523Epoch 00259: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9507 - val_acc: 0.5042
Epoch 261/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6079 - acc: 0.6520Epoch 00260: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9679 - val_acc: 0.5066
Epoch 262/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6331 - acc: 0.6505Epoch 00261: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9353 - val_acc: 0.5066
Epoch 263/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6148 - acc: 0.6515Epoch 00262: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9495 - val_acc: 0.5030
Epoch 264/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5979 - acc: 0.6525Epoch 00263: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9572 - val_acc: 0.5042
Epoch 265/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6031 - acc: 0.6522Epoch 00264: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9596 - val_acc: 0.5054
Epoch 266/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6033 - acc: 0.6523Epoch 00265: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9472 - val_acc: 0.5030
Epoch 267/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6309 - acc: 0.6505Epoch 00266: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9477 - val_acc: 0.5054
Epoch 268/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6012 - acc: 0.6525Epoch 00267: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9395 - val_acc: 0.5054
Epoch 269/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5822 - acc: 0.6535Epoch 00268: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6066 - acc: 0.6519 - val_loss: 6.9404 - val_acc: 0.5066
Epoch 270/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6024 - acc: 0.6522Epoch 00269: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9414 - val_acc: 0.5066
Epoch 271/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5959 - acc: 0.6526Epoch 00270: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9422 - val_acc: 0.5066
Epoch 272/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6211 - acc: 0.6512Epoch 00271: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9484 - val_acc: 0.5066
Epoch 273/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5883 - acc: 0.6532Epoch 00272: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9461 - val_acc: 0.5042
Epoch 274/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6128 - acc: 0.6517Epoch 00273: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9477 - val_acc: 0.5054
Epoch 275/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6089 - acc: 0.6520Epoch 00274: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9522 - val_acc: 0.5054
Epoch 276/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6190 - acc: 0.6514Epoch 00275: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9558 - val_acc: 0.5054
Epoch 277/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6154 - acc: 0.6514Epoch 00276: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9490 - val_acc: 0.5030
Epoch 278/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6151 - acc: 0.6516Epoch 00277: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9373 - val_acc: 0.5054
Epoch 279/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6100 - acc: 0.6518Epoch 00278: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9407 - val_acc: 0.5054
Epoch 280/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6022 - acc: 0.6523Epoch 00279: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9462 - val_acc: 0.5054
Epoch 281/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6000 - acc: 0.6524Epoch 00280: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9493 - val_acc: 0.5042
Epoch 282/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6271 - acc: 0.6509Epoch 00281: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9278 - val_acc: 0.5042
Epoch 283/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6081 - acc: 0.6519Epoch 00282: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9291 - val_acc: 0.5042
Epoch 284/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6138 - acc: 0.6515Epoch 00283: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9294 - val_acc: 0.5042
Epoch 285/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5936 - acc: 0.6528Epoch 00284: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9291 - val_acc: 0.5042
Epoch 286/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5895 - acc: 0.6532Epoch 00285: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9565 - val_acc: 0.5018
Epoch 287/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6209 - acc: 0.6512Epoch 00286: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9514 - val_acc: 0.5006
Epoch 288/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.5995 - acc: 0.6526Epoch 00287: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9549 - val_acc: 0.5006
Epoch 289/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5817 - acc: 0.6537Epoch 00288: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9585 - val_acc: 0.5018
Epoch 290/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6135 - acc: 0.6515Epoch 00289: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9582 - val_acc: 0.5030
Epoch 291/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5842 - acc: 0.6535Epoch 00290: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9603 - val_acc: 0.5006
Epoch 292/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6082 - acc: 0.6519Epoch 00291: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9622 - val_acc: 0.5018
Epoch 293/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6067 - acc: 0.6520Epoch 00292: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9600 - val_acc: 0.5018
Epoch 294/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5943 - acc: 0.6529Epoch 00293: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9555 - val_acc: 0.5006
Epoch 295/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6221 - acc: 0.6510Epoch 00294: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9554 - val_acc: 0.4994
Epoch 296/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5951 - acc: 0.6527Epoch 00295: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9622 - val_acc: 0.5006
Epoch 297/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6052 - acc: 0.6522Epoch 00296: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9522 - val_acc: 0.4982
Epoch 298/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5701 - acc: 0.6544Epoch 00297: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9529 - val_acc: 0.4994
Epoch 299/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5947 - acc: 0.6529Epoch 00298: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9545 - val_acc: 0.5006
Epoch 300/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6124 - acc: 0.6516Epoch 00299: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9526 - val_acc: 0.4994
Epoch 301/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6046 - acc: 0.6521Epoch 00300: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9558 - val_acc: 0.5006
Epoch 302/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6144 - acc: 0.6516Epoch 00301: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6521 - val_loss: 6.9737 - val_acc: 0.5078
Epoch 303/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6333 - acc: 0.6503Epoch 00302: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9670 - val_acc: 0.5066
Epoch 304/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5744 - acc: 0.6541Epoch 00303: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9638 - val_acc: 0.5066
Epoch 305/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6012 - acc: 0.6525Epoch 00304: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9622 - val_acc: 0.5066
Epoch 306/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6190 - acc: 0.6514Epoch 00305: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9645 - val_acc: 0.5078
Epoch 307/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5940 - acc: 0.6528Epoch 00306: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9540 - val_acc: 0.5090
Epoch 308/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5768 - acc: 0.6538Epoch 00307: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9671 - val_acc: 0.5066
Epoch 309/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6083 - acc: 0.6520Epoch 00308: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9700 - val_acc: 0.5078
Epoch 310/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6233 - acc: 0.6509Epoch 00309: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9679 - val_acc: 0.5090
Epoch 311/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6030 - acc: 0.6523Epoch 00310: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9777 - val_acc: 0.5066
Epoch 312/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5900 - acc: 0.6530Epoch 00311: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9708 - val_acc: 0.5090
Epoch 313/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5721 - acc: 0.6541Epoch 00312: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9657 - val_acc: 0.5078
Epoch 314/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6365 - acc: 0.6502Epoch 00313: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9546 - val_acc: 0.5066
Epoch 315/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6071 - acc: 0.6521Epoch 00314: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9519 - val_acc: 0.5078
Epoch 316/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6220 - acc: 0.6512Epoch 00315: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9572 - val_acc: 0.5078
Epoch 317/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6158 - acc: 0.6514Epoch 00316: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9415 - val_acc: 0.5078
Epoch 318/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6143 - acc: 0.6515Epoch 00317: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9410 - val_acc: 0.5078
Epoch 319/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6039 - acc: 0.6521Epoch 00318: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9413 - val_acc: 0.5078
Epoch 320/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6046 - acc: 0.6521Epoch 00319: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9428 - val_acc: 0.5090
Epoch 321/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6133 - acc: 0.6516Epoch 00320: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9442 - val_acc: 0.5090
Epoch 322/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5852 - acc: 0.6535Epoch 00321: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9431 - val_acc: 0.5078
Epoch 323/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6036 - acc: 0.6523Epoch 00322: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9479 - val_acc: 0.5078
Epoch 324/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6334 - acc: 0.6503Epoch 00323: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9500 - val_acc: 0.5102
Epoch 325/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.5998 - acc: 0.6526Epoch 00324: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9521 - val_acc: 0.5102
Epoch 326/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6070 - acc: 0.6520Epoch 00325: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9395 - val_acc: 0.5078
Epoch 327/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6094 - acc: 0.6518Epoch 00326: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9400 - val_acc: 0.5078
Epoch 328/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6043 - acc: 0.6523Epoch 00327: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9593 - val_acc: 0.5102
Epoch 329/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5992 - acc: 0.6526Epoch 00328: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9521 - val_acc: 0.5090
Epoch 330/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6247 - acc: 0.6508Epoch 00329: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9398 - val_acc: 0.5078
Epoch 331/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6226 - acc: 0.6511Epoch 00330: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9606 - val_acc: 0.5090
Epoch 332/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6058 - acc: 0.6522Epoch 00331: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9600 - val_acc: 0.5090
Epoch 333/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5983 - acc: 0.6526Epoch 00332: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9631 - val_acc: 0.5090
Epoch 334/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6123 - acc: 0.6518Epoch 00333: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9616 - val_acc: 0.5090
Epoch 335/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6123 - acc: 0.6518Epoch 00334: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9680 - val_acc: 0.5090
Epoch 336/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6023 - acc: 0.6524Epoch 00335: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9671 - val_acc: 0.5090
Epoch 337/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6046 - acc: 0.6521Epoch 00336: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9612 - val_acc: 0.5114
Epoch 338/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6099 - acc: 0.6518Epoch 00337: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9718 - val_acc: 0.5114
Epoch 339/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5852 - acc: 0.6535Epoch 00338: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9643 - val_acc: 0.5126
Epoch 340/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5954 - acc: 0.6526Epoch 00339: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6519 - val_loss: 6.9620 - val_acc: 0.5066
Epoch 341/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6044 - acc: 0.6522Epoch 00340: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6519 - val_loss: 6.9623 - val_acc: 0.5090
Epoch 342/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6259 - acc: 0.6508Epoch 00341: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9532 - val_acc: 0.5066
Epoch 343/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6071 - acc: 0.6521Epoch 00342: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9624 - val_acc: 0.5054
Epoch 344/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6025 - acc: 0.6522Epoch 00343: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9535 - val_acc: 0.5054
Epoch 345/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6021 - acc: 0.6523Epoch 00344: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9544 - val_acc: 0.5066
Epoch 346/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6080 - acc: 0.6520Epoch 00345: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9652 - val_acc: 0.5054
Epoch 347/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6035 - acc: 0.6523Epoch 00346: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9536 - val_acc: 0.5042
Epoch 348/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5638 - acc: 0.6546Epoch 00347: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9550 - val_acc: 0.5054
Epoch 349/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6008 - acc: 0.6523Epoch 00348: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9562 - val_acc: 0.5054
Epoch 350/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5756 - acc: 0.6540Epoch 00349: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9558 - val_acc: 0.5054
Epoch 351/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6271 - acc: 0.6509Epoch 00350: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9563 - val_acc: 0.5054
Epoch 352/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6000 - acc: 0.6525Epoch 00351: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9624 - val_acc: 0.5054
Epoch 353/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6057 - acc: 0.6522Epoch 00352: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9778 - val_acc: 0.5054
Epoch 354/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6063 - acc: 0.6520Epoch 00353: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9627 - val_acc: 0.5066
Epoch 355/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6046 - acc: 0.6523Epoch 00354: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9501 - val_acc: 0.5042
Epoch 356/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5943 - acc: 0.6529Epoch 00355: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9473 - val_acc: 0.5054
Epoch 357/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6273 - acc: 0.6508Epoch 00356: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9493 - val_acc: 0.5090
Epoch 358/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6152 - acc: 0.6516Epoch 00357: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9506 - val_acc: 0.5090
Epoch 359/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6175 - acc: 0.6513Epoch 00358: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9514 - val_acc: 0.5090
Epoch 360/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5827 - acc: 0.6535Epoch 00359: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9499 - val_acc: 0.5078
Epoch 361/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6216 - acc: 0.6512Epoch 00360: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9600 - val_acc: 0.5078
Epoch 362/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6071 - acc: 0.6519Epoch 00361: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9598 - val_acc: 0.5078
Epoch 363/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6446 - acc: 0.6496Epoch 00362: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9591 - val_acc: 0.5078
Epoch 364/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5815 - acc: 0.6535Epoch 00363: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9597 - val_acc: 0.5078
Epoch 365/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6153 - acc: 0.6515Epoch 00364: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9608 - val_acc: 0.5078
Epoch 366/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6070 - acc: 0.6520Epoch 00365: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9622 - val_acc: 0.5090
Epoch 367/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6046 - acc: 0.6523Epoch 00366: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9579 - val_acc: 0.5066
Epoch 368/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6073 - acc: 0.6521Epoch 00367: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9543 - val_acc: 0.5066
Epoch 369/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6201 - acc: 0.6513Epoch 00368: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9604 - val_acc: 0.5042
Epoch 370/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5948 - acc: 0.6528Epoch 00369: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6059 - acc: 0.6521 - val_loss: 6.9687 - val_acc: 0.5042
Epoch 371/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6004 - acc: 0.6525Epoch 00370: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9624 - val_acc: 0.5054
Epoch 372/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6091 - acc: 0.6518Epoch 00371: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9855 - val_acc: 0.5042
Epoch 373/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5918 - acc: 0.6531Epoch 00372: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9744 - val_acc: 0.5054
Epoch 374/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6336 - acc: 0.6505Epoch 00373: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9727 - val_acc: 0.5066
Epoch 375/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5938 - acc: 0.6529Epoch 00374: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9732 - val_acc: 0.5066
Epoch 376/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6219 - acc: 0.6512Epoch 00375: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9827 - val_acc: 0.5066
Epoch 377/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6161 - acc: 0.6514Epoch 00376: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6519 - val_loss: 6.9759 - val_acc: 0.5066
Epoch 378/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6123 - acc: 0.6516Epoch 00377: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9745 - val_acc: 0.5066
Epoch 379/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5834 - acc: 0.6536Epoch 00378: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9745 - val_acc: 0.5066
Epoch 380/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6116 - acc: 0.6518Epoch 00379: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9734 - val_acc: 0.5066
Epoch 381/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5768 - acc: 0.6540Epoch 00380: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9740 - val_acc: 0.5078
Epoch 382/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6176 - acc: 0.6515Epoch 00381: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9720 - val_acc: 0.5078
Epoch 383/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5983 - acc: 0.6525Epoch 00382: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9721 - val_acc: 0.5078
Epoch 384/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6046 - acc: 0.6521Epoch 00383: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9730 - val_acc: 0.5078
Epoch 385/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6118 - acc: 0.6518Epoch 00384: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9741 - val_acc: 0.5054
Epoch 386/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5792 - acc: 0.6538Epoch 00385: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9713 - val_acc: 0.5066
Epoch 387/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6372 - acc: 0.6502Epoch 00386: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9718 - val_acc: 0.5066
Epoch 388/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6214 - acc: 0.6512Epoch 00387: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9649 - val_acc: 0.5066
Epoch 389/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6138 - acc: 0.6517Epoch 00388: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9651 - val_acc: 0.5066
Epoch 390/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5921 - acc: 0.6529Epoch 00389: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9717 - val_acc: 0.5066
Epoch 391/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6273 - acc: 0.6507Epoch 00390: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9743 - val_acc: 0.5078
Epoch 392/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5703 - acc: 0.6542Epoch 00391: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9730 - val_acc: 0.5066
Epoch 393/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6273 - acc: 0.6507Epoch 00392: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9762 - val_acc: 0.5054
Epoch 394/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5969 - acc: 0.6526Epoch 00393: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9738 - val_acc: 0.5054
Epoch 395/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6283 - acc: 0.6506Epoch 00394: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9739 - val_acc: 0.5054
Epoch 396/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6161 - acc: 0.6515Epoch 00395: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9554 - val_acc: 0.5078
Epoch 397/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6117 - acc: 0.6518Epoch 00396: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9683 - val_acc: 0.5102
Epoch 398/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6321 - acc: 0.6504Epoch 00397: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9763 - val_acc: 0.5090
Epoch 399/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5862 - acc: 0.6534Epoch 00398: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9718 - val_acc: 0.5090
Epoch 400/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5757 - acc: 0.6540Epoch 00399: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9725 - val_acc: 0.5102
Epoch 401/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6133 - acc: 0.6517Epoch 00400: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9749 - val_acc: 0.5102
Epoch 402/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6057 - acc: 0.6520Epoch 00401: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9710 - val_acc: 0.5102
Epoch 403/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6225 - acc: 0.6510Epoch 00402: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9657 - val_acc: 0.5102
Epoch 404/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5935 - acc: 0.6529Epoch 00403: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9658 - val_acc: 0.5102
Epoch 405/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6046 - acc: 0.6523Epoch 00404: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9663 - val_acc: 0.5102
Epoch 406/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6287 - acc: 0.6508Epoch 00405: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9664 - val_acc: 0.5102
Epoch 407/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6123 - acc: 0.6518Epoch 00406: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9685 - val_acc: 0.5114
Epoch 408/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5817 - acc: 0.6535Epoch 00407: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9673 - val_acc: 0.5114
Epoch 409/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6260 - acc: 0.6509Epoch 00408: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9563 - val_acc: 0.5102
Epoch 410/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5926 - acc: 0.6530Epoch 00409: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9577 - val_acc: 0.5090
Epoch 411/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5722 - acc: 0.6543Epoch 00410: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9579 - val_acc: 0.5090
Epoch 412/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6220 - acc: 0.6510Epoch 00411: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9575 - val_acc: 0.5090
Epoch 413/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5972 - acc: 0.6527Epoch 00412: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9567 - val_acc: 0.5090
Epoch 414/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6095 - acc: 0.6518Epoch 00413: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6054 - acc: 0.6521 - val_loss: 6.9635 - val_acc: 0.5090
Epoch 415/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5737 - acc: 0.6540Epoch 00414: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9615 - val_acc: 0.5090
Epoch 416/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6085 - acc: 0.6519Epoch 00415: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9596 - val_acc: 0.5090
Epoch 417/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6334 - acc: 0.6503Epoch 00416: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9593 - val_acc: 0.5090
Epoch 418/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6042 - acc: 0.6521Epoch 00417: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9600 - val_acc: 0.5078
Epoch 419/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6162 - acc: 0.6514Epoch 00418: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9606 - val_acc: 0.5078
Epoch 420/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6081 - acc: 0.6520Epoch 00419: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6521 - val_loss: 6.9594 - val_acc: 0.5090
Epoch 421/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5996 - acc: 0.6524Epoch 00420: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9580 - val_acc: 0.5090
Epoch 422/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5876 - acc: 0.6531Epoch 00421: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9589 - val_acc: 0.5090
Epoch 423/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6040 - acc: 0.6523Epoch 00422: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6521 - val_loss: 6.9567 - val_acc: 0.5078
Epoch 424/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6211 - acc: 0.6511Epoch 00423: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9650 - val_acc: 0.5066
Epoch 425/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6518Epoch 00424: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9679 - val_acc: 0.5078
Epoch 426/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6025 - acc: 0.6522Epoch 00425: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9640 - val_acc: 0.5066
Epoch 427/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6003 - acc: 0.6524Epoch 00426: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6054 - acc: 0.6521 - val_loss: 6.9688 - val_acc: 0.5066
Epoch 428/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6201 - acc: 0.6512Epoch 00427: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6064 - acc: 0.6521 - val_loss: 6.9546 - val_acc: 0.5090
Epoch 429/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6126 - acc: 0.6516Epoch 00428: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9540 - val_acc: 0.5078
Epoch 430/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6257 - acc: 0.6508Epoch 00429: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9539 - val_acc: 0.5078
Epoch 431/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6157 - acc: 0.6514Epoch 00430: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9541 - val_acc: 0.5078
Epoch 432/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6021 - acc: 0.6523Epoch 00431: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9541 - val_acc: 0.5078
Epoch 433/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5831 - acc: 0.6534Epoch 00432: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9547 - val_acc: 0.5078
Epoch 434/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6118 - acc: 0.6518Epoch 00433: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9644 - val_acc: 0.5066
Epoch 435/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5935 - acc: 0.6528Epoch 00434: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9578 - val_acc: 0.5066
Epoch 436/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6042 - acc: 0.6523Epoch 00435: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6521 - val_loss: 6.9600 - val_acc: 0.5078
Epoch 437/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6123 - acc: 0.6518Epoch 00436: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9599 - val_acc: 0.5054
Epoch 438/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6025 - acc: 0.6522Epoch 00437: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9593 - val_acc: 0.5054
Epoch 439/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6033 - acc: 0.6523Epoch 00438: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9584 - val_acc: 0.5078
Epoch 440/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5931 - acc: 0.6528Epoch 00439: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9561 - val_acc: 0.5078
Epoch 441/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6086 - acc: 0.6520Epoch 00440: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9561 - val_acc: 0.5054
Epoch 442/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5886 - acc: 0.6531Epoch 00441: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9559 - val_acc: 0.5078
Epoch 443/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6100 - acc: 0.6519Epoch 00442: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9558 - val_acc: 0.5054
Epoch 444/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6071 - acc: 0.6519Epoch 00443: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9587 - val_acc: 0.5078
Epoch 445/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5946 - acc: 0.6527Epoch 00444: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9581 - val_acc: 0.5066
Epoch 446/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5897 - acc: 0.6532Epoch 00445: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9596 - val_acc: 0.5078
Epoch 447/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6514Epoch 00446: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9589 - val_acc: 0.5078
Epoch 448/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6136 - acc: 0.6517Epoch 00447: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9608 - val_acc: 0.5078
Epoch 449/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6309 - acc: 0.6506Epoch 00448: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9598 - val_acc: 0.5078
Epoch 450/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6172 - acc: 0.6515Epoch 00449: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9602 - val_acc: 0.5078
Epoch 451/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6033 - acc: 0.6523Epoch 00450: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9607 - val_acc: 0.5078
Epoch 452/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6105 - acc: 0.6517Epoch 00451: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9557 - val_acc: 0.5042
Epoch 453/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6359 - acc: 0.6502Epoch 00452: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9638 - val_acc: 0.5018
Epoch 454/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6219 - acc: 0.6512Epoch 00453: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6521 - val_loss: 6.9619 - val_acc: 0.5054
Epoch 455/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6194 - acc: 0.6512Epoch 00454: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9679 - val_acc: 0.5042
Epoch 456/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6327 - acc: 0.6504Epoch 00455: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9624 - val_acc: 0.5066
Epoch 457/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6107 - acc: 0.6517Epoch 00456: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9622 - val_acc: 0.5066
Epoch 458/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6012 - acc: 0.6525Epoch 00457: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9662 - val_acc: 0.5042
Epoch 459/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6121 - acc: 0.6516Epoch 00458: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9660 - val_acc: 0.5042
Epoch 460/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6186 - acc: 0.6514Epoch 00459: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9658 - val_acc: 0.5102
Epoch 461/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6019 - acc: 0.6524Epoch 00460: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9615 - val_acc: 0.5078
Epoch 462/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6007 - acc: 0.6523Epoch 00461: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9631 - val_acc: 0.5078
Epoch 463/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5935 - acc: 0.6528Epoch 00462: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9675 - val_acc: 0.5090
Epoch 464/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6101 - acc: 0.6519Epoch 00463: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9676 - val_acc: 0.5090
Epoch 465/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6094 - acc: 0.6518Epoch 00464: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9685 - val_acc: 0.5090
Epoch 466/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5950 - acc: 0.6527Epoch 00465: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9683 - val_acc: 0.5090
Epoch 467/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5915 - acc: 0.6531Epoch 00466: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9673 - val_acc: 0.5090
Epoch 468/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6176 - acc: 0.6513Epoch 00467: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9689 - val_acc: 0.5102
Epoch 469/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6100 - acc: 0.6519Epoch 00468: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6066 - acc: 0.6521 - val_loss: 6.9634 - val_acc: 0.5066
Epoch 470/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6322 - acc: 0.6504Epoch 00469: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9652 - val_acc: 0.5078
Epoch 471/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6210 - acc: 0.6512Epoch 00470: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9692 - val_acc: 0.5090
Epoch 472/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5905 - acc: 0.6530Epoch 00471: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9638 - val_acc: 0.5078
Epoch 473/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6024 - acc: 0.6522Epoch 00472: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9638 - val_acc: 0.5078
Epoch 474/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6159 - acc: 0.6514Epoch 00473: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9647 - val_acc: 0.5078
Epoch 475/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6142 - acc: 0.6517Epoch 00474: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9695 - val_acc: 0.5090
Epoch 476/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6025 - acc: 0.6522Epoch 00475: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9750 - val_acc: 0.5066
Epoch 477/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6322 - acc: 0.6505Epoch 00476: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9744 - val_acc: 0.5066
Epoch 478/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6046 - acc: 0.6523Epoch 00477: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9744 - val_acc: 0.5066
Epoch 479/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6212 - acc: 0.6512Epoch 00478: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9761 - val_acc: 0.5078
Epoch 480/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6085 - acc: 0.6519Epoch 00479: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9640 - val_acc: 0.5066
Epoch 481/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6022 - acc: 0.6524Epoch 00480: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9692 - val_acc: 0.5102
Epoch 482/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6063 - acc: 0.6520Epoch 00481: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9670 - val_acc: 0.5078
Epoch 483/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6054 - acc: 0.6522Epoch 00482: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9705 - val_acc: 0.5090
Epoch 484/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6113 - acc: 0.6517Epoch 00483: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9514 - val_acc: 0.5066
Epoch 485/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6057 - acc: 0.6520Epoch 00484: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9497 - val_acc: 0.5102
Epoch 486/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6285 - acc: 0.6508Epoch 00485: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9513 - val_acc: 0.5102
Epoch 487/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5719 - acc: 0.6541Epoch 00486: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9512 - val_acc: 0.5102
Epoch 488/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5975 - acc: 0.6525Epoch 00487: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9529 - val_acc: 0.5114
Epoch 489/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6068 - acc: 0.6520Epoch 00488: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9537 - val_acc: 0.5114
Epoch 490/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6246 - acc: 0.6509Epoch 00489: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9540 - val_acc: 0.5114
Epoch 491/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6107 - acc: 0.6517Epoch 00490: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9545 - val_acc: 0.5114
Epoch 492/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6060 - acc: 0.6520Epoch 00491: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9540 - val_acc: 0.5114
Epoch 493/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5947 - acc: 0.6529Epoch 00492: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9576 - val_acc: 0.5114
Epoch 494/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5998 - acc: 0.6526Epoch 00493: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9501 - val_acc: 0.5126
Epoch 495/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6518Epoch 00494: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9585 - val_acc: 0.5102
Epoch 496/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6099 - acc: 0.6518Epoch 00495: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9584 - val_acc: 0.5114
Epoch 497/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6261 - acc: 0.6509Epoch 00496: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9582 - val_acc: 0.5102
Epoch 498/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6137 - acc: 0.6515Epoch 00497: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9652 - val_acc: 0.5114
Epoch 499/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6039 - acc: 0.6521Epoch 00498: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9656 - val_acc: 0.5114
Epoch 500/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6276 - acc: 0.6509Epoch 00499: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9598 - val_acc: 0.5102
Epoch 501/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6219 - acc: 0.6510Epoch 00500: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9589 - val_acc: 0.5102
Epoch 502/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5945 - acc: 0.6527Epoch 00501: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9603 - val_acc: 0.5126
Epoch 503/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5847 - acc: 0.6535Epoch 00502: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9575 - val_acc: 0.5102
Epoch 504/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6169 - acc: 0.6513Epoch 00503: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9591 - val_acc: 0.5102
Epoch 505/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6124 - acc: 0.6516Epoch 00504: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9622 - val_acc: 0.5126
Epoch 506/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6514Epoch 00505: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9568 - val_acc: 0.5114
Epoch 507/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6246 - acc: 0.6509Epoch 00506: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9537 - val_acc: 0.5114
Epoch 508/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6163 - acc: 0.6515Epoch 00507: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9551 - val_acc: 0.5126
Epoch 509/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6134 - acc: 0.6517Epoch 00508: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9600 - val_acc: 0.5126
Epoch 510/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6097 - acc: 0.6519Epoch 00509: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9572 - val_acc: 0.5102
Epoch 511/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6025 - acc: 0.6522Epoch 00510: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9549 - val_acc: 0.5102
Epoch 512/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6308 - acc: 0.6505Epoch 00511: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9534 - val_acc: 0.5114
Epoch 513/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6058 - acc: 0.6522Epoch 00512: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9569 - val_acc: 0.5078
Epoch 514/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6074 - acc: 0.6519Epoch 00513: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9522 - val_acc: 0.5102
Epoch 515/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6239 - acc: 0.6511Epoch 00514: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9550 - val_acc: 0.5102
Epoch 516/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6074 - acc: 0.6519Epoch 00515: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9536 - val_acc: 0.5102
Epoch 517/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6187 - acc: 0.6512Epoch 00516: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9568 - val_acc: 0.5114
Epoch 518/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6047 - acc: 0.6523Epoch 00517: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9605 - val_acc: 0.5102
Epoch 519/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5971 - acc: 0.6527Epoch 00518: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9618 - val_acc: 0.5114
Epoch 520/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5943 - acc: 0.6528Epoch 00519: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6054 - acc: 0.6521 - val_loss: 6.9571 - val_acc: 0.5102
Epoch 521/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6056 - acc: 0.6522Epoch 00520: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9629 - val_acc: 0.5114
Epoch 522/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5897 - acc: 0.6532Epoch 00521: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9631 - val_acc: 0.5102
Epoch 523/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5955 - acc: 0.6527Epoch 00522: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9626 - val_acc: 0.5102
Epoch 524/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6141 - acc: 0.6517Epoch 00523: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9660 - val_acc: 0.5078
Epoch 525/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5961 - acc: 0.6528Epoch 00524: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9694 - val_acc: 0.5066
Epoch 526/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6165 - acc: 0.6515Epoch 00525: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9706 - val_acc: 0.5054
Epoch 527/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5997 - acc: 0.6524Epoch 00526: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9729 - val_acc: 0.5054
Epoch 528/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6100 - acc: 0.6519Epoch 00527: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9701 - val_acc: 0.5054
Epoch 529/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6210 - acc: 0.6512Epoch 00528: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9719 - val_acc: 0.5066
Epoch 530/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6083 - acc: 0.6520Epoch 00529: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9713 - val_acc: 0.5030
Epoch 531/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6158 - acc: 0.6514Epoch 00530: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9780 - val_acc: 0.5042
Epoch 532/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5961 - acc: 0.6528Epoch 00531: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9789 - val_acc: 0.5042
Epoch 533/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6049 - acc: 0.6521Epoch 00532: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9821 - val_acc: 0.5066
Epoch 534/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6171 - acc: 0.6513Epoch 00533: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9827 - val_acc: 0.5066
Epoch 535/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6421 - acc: 0.6498Epoch 00534: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9827 - val_acc: 0.5066
Epoch 536/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6224 - acc: 0.6512Epoch 00535: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9726 - val_acc: 0.5042
Epoch 537/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6322 - acc: 0.6505Epoch 00536: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9723 - val_acc: 0.5042
Epoch 538/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6237 - acc: 0.6511Epoch 00537: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9725 - val_acc: 0.5042
Epoch 539/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6171 - acc: 0.6513Epoch 00538: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9715 - val_acc: 0.5030
Epoch 540/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5982 - acc: 0.6526Epoch 00539: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9706 - val_acc: 0.5054
Epoch 541/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5992 - acc: 0.6524Epoch 00540: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9731 - val_acc: 0.5054
Epoch 542/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5976 - acc: 0.6527Epoch 00541: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9726 - val_acc: 0.5054
Epoch 543/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6033 - acc: 0.6523Epoch 00542: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9732 - val_acc: 0.5054
Epoch 544/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5885 - acc: 0.6531Epoch 00543: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9793 - val_acc: 0.5054
Epoch 545/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6129 - acc: 0.6517Epoch 00544: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6065 - acc: 0.6521 - val_loss: 6.9765 - val_acc: 0.5030
Epoch 546/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5826 - acc: 0.6535Epoch 00545: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9763 - val_acc: 0.5030
Epoch 547/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6028 - acc: 0.6522Epoch 00546: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9711 - val_acc: 0.5042
Epoch 548/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5900 - acc: 0.6530Epoch 00547: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9709 - val_acc: 0.5042
Epoch 549/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6226 - acc: 0.6512Epoch 00548: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6075 - acc: 0.6521 - val_loss: 6.9828 - val_acc: 0.5018
Epoch 550/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5940 - acc: 0.6528Epoch 00549: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9719 - val_acc: 0.5054
Epoch 551/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6209 - acc: 0.6511Epoch 00550: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9717 - val_acc: 0.5054
Epoch 552/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6046 - acc: 0.6521Epoch 00551: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9712 - val_acc: 0.5054
Epoch 553/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5817 - acc: 0.6535Epoch 00552: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9712 - val_acc: 0.5054
Epoch 554/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5906 - acc: 0.6530Epoch 00553: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9711 - val_acc: 0.5054
Epoch 555/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6320 - acc: 0.6504Epoch 00554: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9711 - val_acc: 0.5054
Epoch 556/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5977 - acc: 0.6527Epoch 00555: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9762 - val_acc: 0.5066
Epoch 557/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6012 - acc: 0.6525Epoch 00556: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9732 - val_acc: 0.5078
Epoch 558/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6186 - acc: 0.6514Epoch 00557: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9751 - val_acc: 0.5078
Epoch 559/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6150 - acc: 0.6516Epoch 00558: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9752 - val_acc: 0.5078
Epoch 560/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6014 - acc: 0.6523Epoch 00559: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9731 - val_acc: 0.5078
Epoch 561/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6008 - acc: 0.6525Epoch 00560: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9708 - val_acc: 0.5078
Epoch 562/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5887 - acc: 0.6532Epoch 00561: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9750 - val_acc: 0.5066
Epoch 563/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6186 - acc: 0.6514Epoch 00562: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9753 - val_acc: 0.5078
Epoch 564/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6209 - acc: 0.6512Epoch 00563: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9765 - val_acc: 0.5078
Epoch 565/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6201 - acc: 0.6513Epoch 00564: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9768 - val_acc: 0.5078
Epoch 566/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5871 - acc: 0.6532Epoch 00565: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9693 - val_acc: 0.5090
Epoch 567/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6313 - acc: 0.6506Epoch 00566: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9692 - val_acc: 0.5090
Epoch 568/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5977 - acc: 0.6527Epoch 00567: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9689 - val_acc: 0.5090
Epoch 569/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5961 - acc: 0.6526Epoch 00568: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9677 - val_acc: 0.5090
Epoch 570/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6093 - acc: 0.6518Epoch 00569: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9669 - val_acc: 0.5078
Epoch 571/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6000 - acc: 0.6524Epoch 00570: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9671 - val_acc: 0.5078
Epoch 572/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6072 - acc: 0.6521Epoch 00571: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9696 - val_acc: 0.5066
Epoch 573/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6070 - acc: 0.6521Epoch 00572: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9702 - val_acc: 0.5078
Epoch 574/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6090 - acc: 0.6520Epoch 00573: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9714 - val_acc: 0.5090
Epoch 575/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5996 - acc: 0.6524Epoch 00574: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9592 - val_acc: 0.5054
Epoch 576/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6107 - acc: 0.6517Epoch 00575: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9598 - val_acc: 0.5054
Epoch 577/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6027 - acc: 0.6524Epoch 00576: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9664 - val_acc: 0.5042
Epoch 578/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6071 - acc: 0.6519Epoch 00577: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9650 - val_acc: 0.5042
Epoch 579/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5971 - acc: 0.6527Epoch 00578: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9647 - val_acc: 0.5042
Epoch 580/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6137 - acc: 0.6515Epoch 00579: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9641 - val_acc: 0.5042
Epoch 581/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5790 - acc: 0.6537Epoch 00580: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9623 - val_acc: 0.5042
Epoch 582/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6060 - acc: 0.6520Epoch 00581: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9626 - val_acc: 0.5042
Epoch 583/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5712 - acc: 0.6542Epoch 00582: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9634 - val_acc: 0.5042
Epoch 584/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6125 - acc: 0.6518Epoch 00583: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9641 - val_acc: 0.5042
Epoch 585/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5980 - acc: 0.6527Epoch 00584: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9650 - val_acc: 0.5054
Epoch 586/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5794 - acc: 0.6538Epoch 00585: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9653 - val_acc: 0.5054
Epoch 587/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6095 - acc: 0.6520Epoch 00586: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9657 - val_acc: 0.5066
Epoch 588/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6154 - acc: 0.6516Epoch 00587: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9661 - val_acc: 0.5066
Epoch 589/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5917 - acc: 0.6529Epoch 00588: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9698 - val_acc: 0.5066
Epoch 590/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6360 - acc: 0.6503Epoch 00589: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9700 - val_acc: 0.5090
Epoch 591/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6129 - acc: 0.6516Epoch 00590: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9604 - val_acc: 0.5054
Epoch 592/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6061 - acc: 0.6522Epoch 00591: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9596 - val_acc: 0.5054
Epoch 593/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5882 - acc: 0.6533Epoch 00592: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9596 - val_acc: 0.5054
Epoch 594/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6021 - acc: 0.6523Epoch 00593: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9574 - val_acc: 0.5054
Epoch 595/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6222 - acc: 0.6512Epoch 00594: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9607 - val_acc: 0.5054
Epoch 596/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6509 - acc: 0.6494Epoch 00595: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9618 - val_acc: 0.5078
Epoch 597/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6157 - acc: 0.6514Epoch 00596: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9565 - val_acc: 0.5054
Epoch 598/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6125 - acc: 0.6518Epoch 00597: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9605 - val_acc: 0.5054
Epoch 599/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6189 - acc: 0.6512Epoch 00598: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9598 - val_acc: 0.5054
Epoch 600/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6191 - acc: 0.6512Epoch 00599: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9595 - val_acc: 0.5054
Epoch 601/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5983 - acc: 0.6525Epoch 00600: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9575 - val_acc: 0.5054
Epoch 602/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6334 - acc: 0.6503Epoch 00601: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9503 - val_acc: 0.5066
Epoch 603/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6033 - acc: 0.6523Epoch 00602: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9555 - val_acc: 0.5090
Epoch 604/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5996 - acc: 0.6524Epoch 00603: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9581 - val_acc: 0.5078
Epoch 605/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6021 - acc: 0.6522Epoch 00604: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9557 - val_acc: 0.5090
Epoch 606/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6127 - acc: 0.6516Epoch 00605: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9555 - val_acc: 0.5090
Epoch 607/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6322 - acc: 0.6504Epoch 00606: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9581 - val_acc: 0.5078
Epoch 608/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6070 - acc: 0.6521Epoch 00607: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9594 - val_acc: 0.5090
Epoch 609/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6144 - acc: 0.6515Epoch 00608: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9572 - val_acc: 0.5090
Epoch 610/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6048 - acc: 0.6522Epoch 00609: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9653 - val_acc: 0.5102
Epoch 611/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5886 - acc: 0.6531Epoch 00610: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9658 - val_acc: 0.5078
Epoch 612/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6572 - acc: 0.6488Epoch 00611: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9658 - val_acc: 0.5078
Epoch 613/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6094 - acc: 0.6518Epoch 00612: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9646 - val_acc: 0.5078
Epoch 614/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6285 - acc: 0.6508Epoch 00613: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9645 - val_acc: 0.5078
Epoch 615/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5754 - acc: 0.6541Epoch 00614: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9646 - val_acc: 0.5078
Epoch 616/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6087 - acc: 0.6520Epoch 00615: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9650 - val_acc: 0.5078
Epoch 617/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6070 - acc: 0.6520Epoch 00616: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9731 - val_acc: 0.5030
Epoch 618/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5901 - acc: 0.6530Epoch 00617: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9719 - val_acc: 0.5030
Epoch 619/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6285 - acc: 0.6506Epoch 00618: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9725 - val_acc: 0.5030
Epoch 620/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6070 - acc: 0.6520Epoch 00619: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9749 - val_acc: 0.5030
Epoch 621/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5816 - acc: 0.6535Epoch 00620: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9757 - val_acc: 0.5030
Epoch 622/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5737 - acc: 0.6540Epoch 00621: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9759 - val_acc: 0.5054
Epoch 623/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6321 - acc: 0.6504Epoch 00622: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9771 - val_acc: 0.5054
Epoch 624/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6047 - acc: 0.6522Epoch 00623: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9745 - val_acc: 0.5042
Epoch 625/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6371 - acc: 0.6501Epoch 00624: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9798 - val_acc: 0.5042
Epoch 626/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5862 - acc: 0.6532Epoch 00625: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9737 - val_acc: 0.5054
Epoch 627/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6237 - acc: 0.6511Epoch 00626: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9728 - val_acc: 0.5042
Epoch 628/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5856 - acc: 0.6533Epoch 00627: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9759 - val_acc: 0.5054
Epoch 629/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6210 - acc: 0.6511Epoch 00628: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9774 - val_acc: 0.5054
Epoch 630/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6062 - acc: 0.6520Epoch 00629: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9782 - val_acc: 0.5054
Epoch 631/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6124 - acc: 0.6517Epoch 00630: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6058 - acc: 0.6521 - val_loss: 6.9704 - val_acc: 0.5042
Epoch 632/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6137 - acc: 0.6515Epoch 00631: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9687 - val_acc: 0.5030
Epoch 633/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6139 - acc: 0.6515Epoch 00632: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9685 - val_acc: 0.5030
Epoch 634/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6079 - acc: 0.6521Epoch 00633: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6076 - acc: 0.6521 - val_loss: 6.9697 - val_acc: 0.5054
Epoch 635/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6124 - acc: 0.6518Epoch 00634: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9758 - val_acc: 0.5066
Epoch 636/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6096 - acc: 0.6519Epoch 00635: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9564 - val_acc: 0.5066
Epoch 637/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5844 - acc: 0.6535Epoch 00636: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9659 - val_acc: 0.5066
Epoch 638/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6012 - acc: 0.6524Epoch 00637: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6061 - acc: 0.6521 - val_loss: 6.9843 - val_acc: 0.5078
Epoch 639/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6045 - acc: 0.6521Epoch 00638: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9842 - val_acc: 0.5078
Epoch 640/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6066 - acc: 0.6520Epoch 00639: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9827 - val_acc: 0.5078
Epoch 641/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5881 - acc: 0.6533Epoch 00640: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6076 - acc: 0.6521 - val_loss: 6.9816 - val_acc: 0.5078
Epoch 642/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6512Epoch 00641: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9771 - val_acc: 0.5078
Epoch 643/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6094 - acc: 0.6519Epoch 00642: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6066 - acc: 0.6521 - val_loss: 6.9791 - val_acc: 0.5090
Epoch 644/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6073 - acc: 0.6520Epoch 00643: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6059 - acc: 0.6521 - val_loss: 6.9806 - val_acc: 0.5078
Epoch 645/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6093 - acc: 0.6518Epoch 00644: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9809 - val_acc: 0.5078
Epoch 646/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6518Epoch 00645: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9810 - val_acc: 0.5078
Epoch 647/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6069 - acc: 0.6520Epoch 00646: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9811 - val_acc: 0.5078
Epoch 648/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6076 - acc: 0.6521Epoch 00647: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6064 - acc: 0.6521 - val_loss: 6.9779 - val_acc: 0.5090
Epoch 649/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6160 - acc: 0.6514Epoch 00648: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9788 - val_acc: 0.5090
Epoch 650/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6295 - acc: 0.6505Epoch 00649: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9787 - val_acc: 0.5090
Epoch 651/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6178 - acc: 0.6515Epoch 00650: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6076 - acc: 0.6521 - val_loss: 6.9844 - val_acc: 0.5090
Epoch 652/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5979 - acc: 0.6525Epoch 00651: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9798 - val_acc: 0.5066
Epoch 653/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6300 - acc: 0.6506Epoch 00652: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6061 - acc: 0.6521 - val_loss: 6.9867 - val_acc: 0.5090
Epoch 654/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6085 - acc: 0.6519Epoch 00653: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9865 - val_acc: 0.5090
Epoch 655/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5882 - acc: 0.6533Epoch 00654: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9782 - val_acc: 0.5066
Epoch 656/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6095 - acc: 0.6520Epoch 00655: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9791 - val_acc: 0.5054
Epoch 657/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6033 - acc: 0.6523Epoch 00656: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9694 - val_acc: 0.5078
Epoch 658/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6237 - acc: 0.6511Epoch 00657: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9694 - val_acc: 0.5078
Epoch 659/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6081 - acc: 0.6520Epoch 00658: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9664 - val_acc: 0.5102
Epoch 660/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5791 - acc: 0.6538Epoch 00659: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9665 - val_acc: 0.5102
Epoch 661/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6089 - acc: 0.6520Epoch 00660: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9712 - val_acc: 0.5078
Epoch 662/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6383 - acc: 0.6500Epoch 00661: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9664 - val_acc: 0.5054
Epoch 663/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6045 - acc: 0.6521Epoch 00662: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9745 - val_acc: 0.5066
Epoch 664/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5681 - acc: 0.6545Epoch 00663: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9727 - val_acc: 0.5066
Epoch 665/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6045 - acc: 0.6521Epoch 00664: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9737 - val_acc: 0.5066
Epoch 666/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6096 - acc: 0.6520Epoch 00665: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9696 - val_acc: 0.5066
Epoch 667/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5905 - acc: 0.6530Epoch 00666: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9755 - val_acc: 0.5066
Epoch 668/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6118 - acc: 0.6517Epoch 00667: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9760 - val_acc: 0.5066
Epoch 669/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6173 - acc: 0.6513Epoch 00668: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9760 - val_acc: 0.5066
Epoch 670/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5802 - acc: 0.6536Epoch 00669: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9764 - val_acc: 0.5066
Epoch 671/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5749 - acc: 0.6541Epoch 00670: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9737 - val_acc: 0.5078
Epoch 672/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6048 - acc: 0.6523Epoch 00671: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9737 - val_acc: 0.5042
Epoch 673/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5992 - acc: 0.6526Epoch 00672: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9689 - val_acc: 0.5042
Epoch 674/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5717 - acc: 0.6543Epoch 00673: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9736 - val_acc: 0.5054
Epoch 675/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6021 - acc: 0.6523Epoch 00674: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9656 - val_acc: 0.5078
Epoch 676/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6024 - acc: 0.6524Epoch 00675: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9656 - val_acc: 0.5078
Epoch 677/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5931 - acc: 0.6528Epoch 00676: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9663 - val_acc: 0.5078
Epoch 678/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6348 - acc: 0.6504Epoch 00677: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9660 - val_acc: 0.5078
Epoch 679/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5653 - acc: 0.6545Epoch 00678: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9682 - val_acc: 0.5078
Epoch 680/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6436 - acc: 0.6498Epoch 00679: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9682 - val_acc: 0.5078
Epoch 681/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6237 - acc: 0.6511Epoch 00680: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9673 - val_acc: 0.5078
Epoch 682/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6163 - acc: 0.6514Epoch 00681: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9693 - val_acc: 0.5078
Epoch 683/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6038 - acc: 0.6521Epoch 00682: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9696 - val_acc: 0.5078
Epoch 684/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6202 - acc: 0.6511Epoch 00683: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9698 - val_acc: 0.5078
Epoch 685/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6150 - acc: 0.6516Epoch 00684: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9649 - val_acc: 0.5090
Epoch 686/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6250 - acc: 0.6508Epoch 00685: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9764 - val_acc: 0.5054
Epoch 687/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6123 - acc: 0.6516Epoch 00686: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9759 - val_acc: 0.5054
Epoch 688/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6028 - acc: 0.6524Epoch 00687: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9710 - val_acc: 0.5054
Epoch 689/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6038 - acc: 0.6523Epoch 00688: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9698 - val_acc: 0.5066
Epoch 690/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6236 - acc: 0.6511Epoch 00689: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9698 - val_acc: 0.5066
Epoch 691/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6112 - acc: 0.6517Epoch 00690: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9701 - val_acc: 0.5066
Epoch 692/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6348 - acc: 0.6504Epoch 00691: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9706 - val_acc: 0.5078
Epoch 693/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6114 - acc: 0.6518Epoch 00692: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6064 - acc: 0.6521 - val_loss: 6.9745 - val_acc: 0.5078
Epoch 694/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5881 - acc: 0.6533Epoch 00693: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6076 - acc: 0.6521 - val_loss: 6.9746 - val_acc: 0.5078
Epoch 695/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5885 - acc: 0.6532Epoch 00694: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9797 - val_acc: 0.5054
Epoch 696/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6088 - acc: 0.6518Epoch 00695: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9757 - val_acc: 0.5078
Epoch 697/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5986 - acc: 0.6526Epoch 00696: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9735 - val_acc: 0.5066
Epoch 698/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6001 - acc: 0.6525Epoch 00697: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9723 - val_acc: 0.5066
Epoch 699/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5985 - acc: 0.6525Epoch 00698: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9730 - val_acc: 0.5066
Epoch 700/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6060 - acc: 0.6520Epoch 00699: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9721 - val_acc: 0.5066
Epoch 701/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6043 - acc: 0.6523Epoch 00700: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9732 - val_acc: 0.5066
Epoch 702/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5941 - acc: 0.6529Epoch 00701: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9727 - val_acc: 0.5066
Epoch 703/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6334 - acc: 0.6503Epoch 00702: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9626 - val_acc: 0.5054
Epoch 704/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6210 - acc: 0.6511Epoch 00703: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9664 - val_acc: 0.5090
Epoch 705/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6061 - acc: 0.6522Epoch 00704: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9682 - val_acc: 0.5090
Epoch 706/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6043 - acc: 0.6521Epoch 00705: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9636 - val_acc: 0.5090
Epoch 707/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5931 - acc: 0.6530Epoch 00706: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9639 - val_acc: 0.5090
Epoch 708/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6001 - acc: 0.6525Epoch 00707: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9647 - val_acc: 0.5078
Epoch 709/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6061 - acc: 0.6522Epoch 00708: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9651 - val_acc: 0.5078
Epoch 710/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6104 - acc: 0.6519Epoch 00709: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6054 - acc: 0.6521 - val_loss: 6.9694 - val_acc: 0.5102
Epoch 711/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6036 - acc: 0.6522Epoch 00710: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9674 - val_acc: 0.5102
Epoch 712/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6094 - acc: 0.6518Epoch 00711: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9637 - val_acc: 0.5066
Epoch 713/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5799 - acc: 0.6537Epoch 00712: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6064 - acc: 0.6521 - val_loss: 6.9685 - val_acc: 0.5078
Epoch 714/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5780 - acc: 0.6537Epoch 00713: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9685 - val_acc: 0.5078
Epoch 715/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6026 - acc: 0.6524Epoch 00714: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6075 - acc: 0.6521 - val_loss: 6.9654 - val_acc: 0.5066
Epoch 716/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6175 - acc: 0.6513Epoch 00715: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9634 - val_acc: 0.5066
Epoch 717/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5991 - acc: 0.6526Epoch 00716: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9647 - val_acc: 0.5066
Epoch 718/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6061 - acc: 0.6522Epoch 00717: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9653 - val_acc: 0.5066
Epoch 719/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5782 - acc: 0.6539Epoch 00718: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9656 - val_acc: 0.5066
Epoch 720/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6198 - acc: 0.6512Epoch 00719: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9660 - val_acc: 0.5066
Epoch 721/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6195 - acc: 0.6513Epoch 00720: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9665 - val_acc: 0.5078
Epoch 722/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6059 - acc: 0.6520Epoch 00721: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9565 - val_acc: 0.5054
Epoch 723/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5982 - acc: 0.6525Epoch 00722: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9570 - val_acc: 0.5054
Epoch 724/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6060 - acc: 0.6520Epoch 00723: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9574 - val_acc: 0.5054
Epoch 725/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5926 - acc: 0.6530Epoch 00724: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9549 - val_acc: 0.5054
Epoch 726/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6133 - acc: 0.6517Epoch 00725: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9550 - val_acc: 0.5054
Epoch 727/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6210 - acc: 0.6512Epoch 00726: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9553 - val_acc: 0.5054
Epoch 728/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6141 - acc: 0.6517Epoch 00727: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9574 - val_acc: 0.5066
Epoch 729/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6088 - acc: 0.6518Epoch 00728: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9616 - val_acc: 0.5042
Epoch 730/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5907 - acc: 0.6531Epoch 00729: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9574 - val_acc: 0.5042
Epoch 731/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6158 - acc: 0.6514Epoch 00730: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9590 - val_acc: 0.5054
Epoch 732/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6514Epoch 00731: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9566 - val_acc: 0.5042
Epoch 733/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6321 - acc: 0.6505Epoch 00732: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9631 - val_acc: 0.5030
Epoch 734/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6397 - acc: 0.6501Epoch 00733: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9543 - val_acc: 0.5042
Epoch 735/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6213 - acc: 0.6512Epoch 00734: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9544 - val_acc: 0.5042
Epoch 736/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5980 - acc: 0.6527Epoch 00735: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9543 - val_acc: 0.5042
Epoch 737/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6247 - acc: 0.6508Epoch 00736: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9547 - val_acc: 0.5042
Epoch 738/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6104 - acc: 0.6517Epoch 00737: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9553 - val_acc: 0.5042
Epoch 739/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6150 - acc: 0.6516Epoch 00738: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9582 - val_acc: 0.5054
Epoch 740/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6175 - acc: 0.6515Epoch 00739: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9650 - val_acc: 0.5066
Epoch 741/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6334 - acc: 0.6503Epoch 00740: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9559 - val_acc: 0.5078
Epoch 742/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6112 - acc: 0.6519Epoch 00741: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9587 - val_acc: 0.5078
Epoch 743/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6120 - acc: 0.6518Epoch 00742: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9608 - val_acc: 0.5102
Epoch 744/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5937 - acc: 0.6529Epoch 00743: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9606 - val_acc: 0.5102
Epoch 745/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5926 - acc: 0.6528Epoch 00744: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9609 - val_acc: 0.5102
Epoch 746/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6060 - acc: 0.6520Epoch 00745: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9605 - val_acc: 0.5102
Epoch 747/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5940 - acc: 0.6528Epoch 00746: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9605 - val_acc: 0.5102
Epoch 748/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5744 - acc: 0.6541Epoch 00747: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9666 - val_acc: 0.5042
Epoch 749/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6086 - acc: 0.6520Epoch 00748: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9640 - val_acc: 0.5042
Epoch 750/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6057 - acc: 0.6520Epoch 00749: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9681 - val_acc: 0.5042
Epoch 751/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6028 - acc: 0.6524Epoch 00750: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9656 - val_acc: 0.5042
Epoch 752/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6138 - acc: 0.6515Epoch 00751: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9685 - val_acc: 0.5042
Epoch 753/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6102 - acc: 0.6519Epoch 00752: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9682 - val_acc: 0.5042
Epoch 754/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6261 - acc: 0.6508Epoch 00753: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9768 - val_acc: 0.4982
Epoch 755/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6028 - acc: 0.6522Epoch 00754: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9782 - val_acc: 0.4982
Epoch 756/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5956 - acc: 0.6528Epoch 00755: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9740 - val_acc: 0.4994
Epoch 757/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6028 - acc: 0.6522Epoch 00756: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9766 - val_acc: 0.5006
Epoch 758/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6079 - acc: 0.6521Epoch 00757: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9728 - val_acc: 0.4994
Epoch 759/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5902 - acc: 0.6531Epoch 00758: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9733 - val_acc: 0.4994
Epoch 760/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6088 - acc: 0.6518Epoch 00759: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9707 - val_acc: 0.5018
Epoch 761/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6213 - acc: 0.6512Epoch 00760: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9697 - val_acc: 0.5018
Epoch 762/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6018 - acc: 0.6523Epoch 00761: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9711 - val_acc: 0.5018
Epoch 763/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6000 - acc: 0.6524Epoch 00762: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9714 - val_acc: 0.5018
Epoch 764/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5821 - acc: 0.6535Epoch 00763: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9728 - val_acc: 0.5030
Epoch 765/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6005 - acc: 0.6525Epoch 00764: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9704 - val_acc: 0.5018
Epoch 766/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5752 - acc: 0.6541Epoch 00765: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9682 - val_acc: 0.5030
Epoch 767/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6107 - acc: 0.6519Epoch 00766: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9761 - val_acc: 0.5006
Epoch 768/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5955 - acc: 0.6527Epoch 00767: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9837 - val_acc: 0.5006
Epoch 769/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6237 - acc: 0.6511Epoch 00768: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9792 - val_acc: 0.5006
Epoch 770/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5989 - acc: 0.6524Epoch 00769: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9792 - val_acc: 0.5006
Epoch 771/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6067 - acc: 0.6520Epoch 00770: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9796 - val_acc: 0.5006
Epoch 772/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6231 - acc: 0.6509Epoch 00771: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9803 - val_acc: 0.5018
Epoch 773/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6096 - acc: 0.6520Epoch 00772: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9850 - val_acc: 0.4994
Epoch 774/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5953 - acc: 0.6528Epoch 00773: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9808 - val_acc: 0.5018
Epoch 775/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6120 - acc: 0.6518Epoch 00774: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9808 - val_acc: 0.5018
Epoch 776/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5826 - acc: 0.6535Epoch 00775: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9817 - val_acc: 0.5018
Epoch 777/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6126 - acc: 0.6516Epoch 00776: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9820 - val_acc: 0.5042
Epoch 778/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6175 - acc: 0.6515Epoch 00777: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9688 - val_acc: 0.5006
Epoch 779/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6093 - acc: 0.6520Epoch 00778: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9683 - val_acc: 0.5006
Epoch 780/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6081 - acc: 0.6519Epoch 00779: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9693 - val_acc: 0.5006
Epoch 781/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5986 - acc: 0.6526Epoch 00780: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9610 - val_acc: 0.4994
Epoch 782/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6189 - acc: 0.6512Epoch 00781: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9603 - val_acc: 0.5006
Epoch 783/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5911 - acc: 0.6529Epoch 00782: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9600 - val_acc: 0.5006
Epoch 784/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6025 - acc: 0.6524Epoch 00783: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9613 - val_acc: 0.5042
Epoch 785/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5976 - acc: 0.6527Epoch 00784: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9699 - val_acc: 0.5006
Epoch 786/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6185 - acc: 0.6512Epoch 00785: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9700 - val_acc: 0.5006
Epoch 787/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6089 - acc: 0.6518Epoch 00786: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9704 - val_acc: 0.5006
Epoch 788/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5822 - acc: 0.6535Epoch 00787: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9721 - val_acc: 0.5006
Epoch 789/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6050 - acc: 0.6521Epoch 00788: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9717 - val_acc: 0.5006
Epoch 790/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5986 - acc: 0.6526Epoch 00789: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9728 - val_acc: 0.5018
Epoch 791/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6036 - acc: 0.6522Epoch 00790: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9714 - val_acc: 0.5030
Epoch 792/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5802 - acc: 0.6536Epoch 00791: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9710 - val_acc: 0.5006
Epoch 793/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6446 - acc: 0.6496Epoch 00792: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9680 - val_acc: 0.5006
Epoch 794/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6015 - acc: 0.6524Epoch 00793: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9686 - val_acc: 0.5018
Epoch 795/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5995 - acc: 0.6526Epoch 00794: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9687 - val_acc: 0.5018
Epoch 796/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5813 - acc: 0.6537Epoch 00795: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9703 - val_acc: 0.5042
Epoch 797/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6182 - acc: 0.6512Epoch 00796: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9713 - val_acc: 0.5042
Epoch 798/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6514Epoch 00797: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9716 - val_acc: 0.5042
Epoch 799/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6514Epoch 00798: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9696 - val_acc: 0.5018
Epoch 800/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6185 - acc: 0.6512Epoch 00799: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9693 - val_acc: 0.5018
Epoch 801/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6162 - acc: 0.6514Epoch 00800: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9692 - val_acc: 0.5018
Epoch 802/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5990 - acc: 0.6524Epoch 00801: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9700 - val_acc: 0.5042
Epoch 803/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6409 - acc: 0.6498Epoch 00802: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9700 - val_acc: 0.5042
Epoch 804/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6060 - acc: 0.6520Epoch 00803: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9700 - val_acc: 0.5042
Epoch 805/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6285 - acc: 0.6506Epoch 00804: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9700 - val_acc: 0.5042
Epoch 806/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6316 - acc: 0.6505Epoch 00805: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9700 - val_acc: 0.5042
Epoch 807/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6080 - acc: 0.6519Epoch 00806: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6066 - acc: 0.6519 - val_loss: 6.9724 - val_acc: 0.5042
Epoch 808/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6017 - acc: 0.6523Epoch 00807: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9717 - val_acc: 0.5042
Epoch 809/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5879 - acc: 0.6531Epoch 00808: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9725 - val_acc: 0.5042
Epoch 810/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6077 - acc: 0.6521Epoch 00809: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9577 - val_acc: 0.5042
Epoch 811/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6175 - acc: 0.6513Epoch 00810: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9671 - val_acc: 0.5018
Epoch 812/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5964 - acc: 0.6528Epoch 00811: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9614 - val_acc: 0.5042
Epoch 813/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6085 - acc: 0.6519Epoch 00812: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9615 - val_acc: 0.5042
Epoch 814/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6014 - acc: 0.6523Epoch 00813: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9647 - val_acc: 0.5042
Epoch 815/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5899 - acc: 0.6532Epoch 00814: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9629 - val_acc: 0.5042
Epoch 816/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5983 - acc: 0.6525Epoch 00815: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9635 - val_acc: 0.5042
Epoch 817/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5925 - acc: 0.6528Epoch 00816: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9676 - val_acc: 0.5054
Epoch 818/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6123 - acc: 0.6518Epoch 00817: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9634 - val_acc: 0.5042
Epoch 819/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5979 - acc: 0.6525Epoch 00818: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9640 - val_acc: 0.5042
Epoch 820/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5948 - acc: 0.6528Epoch 00819: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9612 - val_acc: 0.5042
Epoch 821/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6009 - acc: 0.6525Epoch 00820: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9631 - val_acc: 0.5042
Epoch 822/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6298 - acc: 0.6505Epoch 00821: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9619 - val_acc: 0.5042
Epoch 823/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6124 - acc: 0.6516Epoch 00822: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9620 - val_acc: 0.5042
Epoch 824/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6175 - acc: 0.6513Epoch 00823: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9620 - val_acc: 0.5042
Epoch 825/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6099 - acc: 0.6518Epoch 00824: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9627 - val_acc: 0.5054
Epoch 826/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6017 - acc: 0.6523Epoch 00825: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9626 - val_acc: 0.5054
Epoch 827/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6067 - acc: 0.6520Epoch 00826: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9631 - val_acc: 0.5054
Epoch 828/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6135 - acc: 0.6515Epoch 00827: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9635 - val_acc: 0.5066
Epoch 829/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6224 - acc: 0.6512Epoch 00828: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9605 - val_acc: 0.5054
Epoch 830/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5817 - acc: 0.6537Epoch 00829: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9621 - val_acc: 0.5030
Epoch 831/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6059 - acc: 0.6520Epoch 00830: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9588 - val_acc: 0.5030
Epoch 832/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5737 - acc: 0.6540Epoch 00831: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9587 - val_acc: 0.5030
Epoch 833/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6249 - acc: 0.6510Epoch 00832: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9587 - val_acc: 0.5030
Epoch 834/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6520Epoch 00833: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9588 - val_acc: 0.5030
Epoch 835/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6203 - acc: 0.6513Epoch 00834: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9588 - val_acc: 0.5030
Epoch 836/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6189 - acc: 0.6514Epoch 00835: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9597 - val_acc: 0.5030
Epoch 837/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6236 - acc: 0.6509Epoch 00836: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9593 - val_acc: 0.5030
Epoch 838/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6175 - acc: 0.6513Epoch 00837: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9587 - val_acc: 0.5042
Epoch 839/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6066 - acc: 0.6521Epoch 00838: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9608 - val_acc: 0.5042
Epoch 840/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6093 - acc: 0.6519Epoch 00839: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9543 - val_acc: 0.5042
Epoch 841/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5979 - acc: 0.6525Epoch 00840: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9555 - val_acc: 0.5042
Epoch 842/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6127 - acc: 0.6518Epoch 00841: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9545 - val_acc: 0.5042
Epoch 843/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6073 - acc: 0.6521Epoch 00842: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9557 - val_acc: 0.5054
Epoch 844/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6032 - acc: 0.6522Epoch 00843: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9560 - val_acc: 0.5054
Epoch 845/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6067 - acc: 0.6520Epoch 00844: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9567 - val_acc: 0.5054
Epoch 846/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5892 - acc: 0.6532Epoch 00845: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9572 - val_acc: 0.5066
Epoch 847/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5960 - acc: 0.6528Epoch 00846: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9584 - val_acc: 0.5054
Epoch 848/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6344 - acc: 0.6502Epoch 00847: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9580 - val_acc: 0.5054
Epoch 849/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6102 - acc: 0.6518Epoch 00848: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9579 - val_acc: 0.5054
Epoch 850/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6288 - acc: 0.6508- ETA: 1s - loss:Epoch 00849: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9579 - val_acc: 0.5054
Epoch 851/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5954 - acc: 0.6527Epoch 00850: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9579 - val_acc: 0.5054
Epoch 852/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6053 - acc: 0.6522Epoch 00851: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9598 - val_acc: 0.5054
Epoch 853/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6250 - acc: 0.6510Epoch 00852: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9612 - val_acc: 0.5054
Epoch 854/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5927 - acc: 0.6530Epoch 00853: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9613 - val_acc: 0.5054
Epoch 855/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6113 - acc: 0.6517Epoch 00854: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9594 - val_acc: 0.5054
Epoch 856/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6153 - acc: 0.6514Epoch 00855: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9593 - val_acc: 0.5054
Epoch 857/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6398 - acc: 0.6501Epoch 00856: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9604 - val_acc: 0.5042
Epoch 858/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6189 - acc: 0.6512Epoch 00857: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9595 - val_acc: 0.5042
Epoch 859/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6132 - acc: 0.6518Epoch 00858: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9648 - val_acc: 0.5066
Epoch 860/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6076 - acc: 0.6521Epoch 00859: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9645 - val_acc: 0.5066
Epoch 861/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6039 - acc: 0.6521Epoch 00860: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9655 - val_acc: 0.5030
Epoch 862/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6139 - acc: 0.6517Epoch 00861: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9663 - val_acc: 0.5030
Epoch 863/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6359 - acc: 0.6502Epoch 00862: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9679 - val_acc: 0.5030
Epoch 864/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6046 - acc: 0.6521Epoch 00863: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9676 - val_acc: 0.5030
Epoch 865/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5908 - acc: 0.6531Epoch 00864: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6067 - acc: 0.6521 - val_loss: 6.9704 - val_acc: 0.5042
Epoch 866/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6132 - acc: 0.6517Epoch 00865: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9689 - val_acc: 0.5030
Epoch 867/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6123 - acc: 0.6516Epoch 00866: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9698 - val_acc: 0.5042
Epoch 868/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6052 - acc: 0.6522Epoch 00867: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9618 - val_acc: 0.5030
Epoch 869/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5903 - acc: 0.6531Epoch 00868: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6063 - acc: 0.6521 - val_loss: 6.9701 - val_acc: 0.5030
Epoch 870/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5885 - acc: 0.6533Epoch 00869: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9582 - val_acc: 0.5042
Epoch 871/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6028 - acc: 0.6524Epoch 00870: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9594 - val_acc: 0.5054
Epoch 872/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5969 - acc: 0.6528Epoch 00871: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9616 - val_acc: 0.5054
Epoch 873/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6077 - acc: 0.6519Epoch 00872: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9522 - val_acc: 0.5054
Epoch 874/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6239 - acc: 0.6511Epoch 00873: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9546 - val_acc: 0.5054
Epoch 875/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5944 - acc: 0.6529Epoch 00874: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9559 - val_acc: 0.5066
Epoch 876/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5944 - acc: 0.6527Epoch 00875: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9569 - val_acc: 0.5078
Epoch 877/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5881 - acc: 0.6531Epoch 00876: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9573 - val_acc: 0.5078
Epoch 878/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6053 - acc: 0.6522Epoch 00877: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9503 - val_acc: 0.5054
Epoch 879/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6097 - acc: 0.6519Epoch 00878: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9504 - val_acc: 0.5054
Epoch 880/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6100 - acc: 0.6519Epoch 00879: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9505 - val_acc: 0.5054
Epoch 881/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6286 - acc: 0.6506Epoch 00880: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9569 - val_acc: 0.5066
Epoch 882/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6172 - acc: 0.6515Epoch 00881: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9553 - val_acc: 0.5066
Epoch 883/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6004 - acc: 0.6525Epoch 00882: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9554 - val_acc: 0.5066
Epoch 884/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6116 - acc: 0.6518Epoch 00883: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9555 - val_acc: 0.5066
Epoch 885/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5936 - acc: 0.6528Epoch 00884: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9589 - val_acc: 0.5054
Epoch 886/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5955 - acc: 0.6528Epoch 00885: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9584 - val_acc: 0.5054
Epoch 887/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6202 - acc: 0.6511Epoch 00886: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9585 - val_acc: 0.5078
Epoch 888/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6470 - acc: 0.6496Epoch 00887: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9608 - val_acc: 0.5054
Epoch 889/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6064 - acc: 0.6521Epoch 00888: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9692 - val_acc: 0.5030
Epoch 890/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6086 - acc: 0.6520Epoch 00889: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9705 - val_acc: 0.5030
Epoch 891/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6308 - acc: 0.6505Epoch 00890: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9634 - val_acc: 0.5030
Epoch 892/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6187 - acc: 0.6512Epoch 00891: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9634 - val_acc: 0.5030
Epoch 893/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6011 - acc: 0.6523Epoch 00892: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9632 - val_acc: 0.5030
Epoch 894/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5783 - acc: 0.6539Epoch 00893: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9632 - val_acc: 0.5030
Epoch 895/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6190 - acc: 0.6514Epoch 00894: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9643 - val_acc: 0.5030
Epoch 896/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5926 - acc: 0.6528Epoch 00895: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9632 - val_acc: 0.5030
Epoch 897/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6082 - acc: 0.6519Epoch 00896: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9631 - val_acc: 0.5030
Epoch 898/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5916 - acc: 0.6531Epoch 00897: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9660 - val_acc: 0.5030
Epoch 899/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6237 - acc: 0.6511Epoch 00898: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9674 - val_acc: 0.5042
Epoch 900/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6141 - acc: 0.6517Epoch 00899: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9690 - val_acc: 0.5054
Epoch 901/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6066 - acc: 0.6522Epoch 00900: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6068 - acc: 0.6521 - val_loss: 6.9726 - val_acc: 0.5054
Epoch 902/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6066 - acc: 0.6521Epoch 00901: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6066 - acc: 0.6521 - val_loss: 6.9630 - val_acc: 0.5030
Epoch 903/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6264 - acc: 0.6509Epoch 00902: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6074 - acc: 0.6521 - val_loss: 6.9673 - val_acc: 0.5042
Epoch 904/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6066 - acc: 0.6520Epoch 00903: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9667 - val_acc: 0.5042
Epoch 905/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6246 - acc: 0.6508Epoch 00904: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9620 - val_acc: 0.5006
Epoch 906/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5901 - acc: 0.6530Epoch 00905: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9623 - val_acc: 0.5006
Epoch 907/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6200 - acc: 0.6511Epoch 00906: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9616 - val_acc: 0.5006
Epoch 908/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5806 - acc: 0.6536Epoch 00907: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9614 - val_acc: 0.5006
Epoch 909/1000
6660/6680 [============================&gt;.] - ETA: 0s - loss: 5.6021 - acc: 0.6523Epoch 00908: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9613 - val_acc: 0.5006
Epoch 910/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6051 - acc: 0.6522Epoch 00909: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9628 - val_acc: 0.5018
Epoch 911/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5991 - acc: 0.6526Epoch 00910: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9656 - val_acc: 0.5030
Epoch 912/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6075 - acc: 0.6521Epoch 00911: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9667 - val_acc: 0.5030
Epoch 913/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6049 - acc: 0.6522Epoch 00912: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6521 - val_loss: 6.9682 - val_acc: 0.5030
Epoch 914/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6050 - acc: 0.6521Epoch 00913: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9683 - val_acc: 0.5030
Epoch 915/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.5911 - acc: 0.6531Epoch 00914: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9685 - val_acc: 0.5030
Epoch 916/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5922 - acc: 0.6530Epoch 00915: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9502 - val_acc: 0.5006
Epoch 917/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6029 - acc: 0.6522Epoch 00916: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9520 - val_acc: 0.5018
Epoch 918/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5901 - acc: 0.6530Epoch 00917: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9526 - val_acc: 0.5018
Epoch 919/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6174 - acc: 0.6513Epoch 00918: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9517 - val_acc: 0.5018
Epoch 920/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5917 - acc: 0.6531Epoch 00919: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9527 - val_acc: 0.5030
Epoch 921/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6012 - acc: 0.6525Epoch 00920: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9527 - val_acc: 0.5030
Epoch 922/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6096 - acc: 0.6518Epoch 00921: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9528 - val_acc: 0.5030
Epoch 923/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6347 - acc: 0.6504Epoch 00922: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9533 - val_acc: 0.5030
Epoch 924/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6136 - acc: 0.6517Epoch 00923: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9538 - val_acc: 0.5030
Epoch 925/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5980 - acc: 0.6525Epoch 00924: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9505 - val_acc: 0.5006
Epoch 926/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5986 - acc: 0.6525Epoch 00925: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9504 - val_acc: 0.5006
Epoch 927/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6197 - acc: 0.6513Epoch 00926: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9482 - val_acc: 0.5030
Epoch 928/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6088 - acc: 0.6520Epoch 00927: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9497 - val_acc: 0.5030
Epoch 929/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6113 - acc: 0.6518Epoch 00928: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9459 - val_acc: 0.5006
Epoch 930/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6223 - acc: 0.6510Epoch 00929: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9455 - val_acc: 0.5006
Epoch 931/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6149 - acc: 0.6515Epoch 00930: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9460 - val_acc: 0.5006
Epoch 932/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6422 - acc: 0.6499Epoch 00931: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9478 - val_acc: 0.5030
Epoch 933/1000
6390/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5791 - acc: 0.6537Epoch 00932: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9455 - val_acc: 0.5006
Epoch 934/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6022 - acc: 0.6524Epoch 00933: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9507 - val_acc: 0.5018
Epoch 935/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6174 - acc: 0.6515Epoch 00934: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9506 - val_acc: 0.5018
Epoch 936/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5812 - acc: 0.6537Epoch 00935: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9527 - val_acc: 0.5018
Epoch 937/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6089 - acc: 0.6520Epoch 00936: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9535 - val_acc: 0.5006
Epoch 938/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6063 - acc: 0.6520Epoch 00937: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9533 - val_acc: 0.5006
Epoch 939/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6111 - acc: 0.6519Epoch 00938: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9538 - val_acc: 0.5006
Epoch 940/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6015 - acc: 0.6524Epoch 00939: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9540 - val_acc: 0.5006
Epoch 941/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5976 - acc: 0.6527Epoch 00940: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9548 - val_acc: 0.5006
Epoch 942/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5867 - acc: 0.6532Epoch 00941: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9515 - val_acc: 0.4994
Epoch 943/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6347 - acc: 0.6504Epoch 00942: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9535 - val_acc: 0.5006
Epoch 944/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6185 - acc: 0.6512Epoch 00943: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9508 - val_acc: 0.5006
Epoch 945/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5803 - acc: 0.6538Epoch 00944: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9511 - val_acc: 0.5006
Epoch 946/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6250 - acc: 0.6510Epoch 00945: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9515 - val_acc: 0.5006
Epoch 947/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5965 - acc: 0.6526Epoch 00946: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9504 - val_acc: 0.5006
Epoch 948/1000
6630/6680 [============================&gt;.] - ETA: 0s - loss: 5.6105 - acc: 0.6517Epoch 00947: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9499 - val_acc: 0.4994
Epoch 949/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6072 - acc: 0.6521Epoch 00948: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9509 - val_acc: 0.5006
Epoch 950/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6135 - acc: 0.6515Epoch 00949: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9506 - val_acc: 0.5006
Epoch 951/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6127 - acc: 0.6518Epoch 00950: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9509 - val_acc: 0.5006
Epoch 952/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5994 - acc: 0.6524Epoch 00951: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9519 - val_acc: 0.5006
Epoch 953/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5847 - acc: 0.6535Epoch 00952: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9474 - val_acc: 0.5018
Epoch 954/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6037 - acc: 0.6523Epoch 00953: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9482 - val_acc: 0.4994
Epoch 955/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6190 - acc: 0.6514Epoch 00954: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9469 - val_acc: 0.4982
Epoch 956/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6004 - acc: 0.6524Epoch 00955: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9469 - val_acc: 0.4982
Epoch 957/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6115 - acc: 0.6517Epoch 00956: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6070 - acc: 0.6519 - val_loss: 6.9487 - val_acc: 0.4994
Epoch 958/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6546 - acc: 0.6490Epoch 00957: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9485 - val_acc: 0.4994
Epoch 959/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5764 - acc: 0.6540Epoch 00958: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6073 - acc: 0.6521 - val_loss: 6.9475 - val_acc: 0.4982
Epoch 960/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6039 - acc: 0.6521Epoch 00959: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9494 - val_acc: 0.4994
Epoch 961/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5881 - acc: 0.6531Epoch 00960: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9491 - val_acc: 0.4994
Epoch 962/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6262 - acc: 0.6509Epoch 00961: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9482 - val_acc: 0.4982
Epoch 963/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6127 - acc: 0.6516Epoch 00962: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9498 - val_acc: 0.4994
Epoch 964/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6029 - acc: 0.6524Epoch 00963: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9483 - val_acc: 0.4982
Epoch 965/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5817 - acc: 0.6535Epoch 00964: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9490 - val_acc: 0.4982
Epoch 966/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6004 - acc: 0.6524Epoch 00965: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9482 - val_acc: 0.5006
Epoch 967/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5916 - acc: 0.6531Epoch 00966: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9463 - val_acc: 0.4994
Epoch 968/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6124 - acc: 0.6518Epoch 00967: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9457 - val_acc: 0.4982
Epoch 969/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6029 - acc: 0.6524Epoch 00968: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9457 - val_acc: 0.4982
Epoch 970/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.6023 - acc: 0.6522Epoch 00969: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6069 - acc: 0.6519 - val_loss: 6.9524 - val_acc: 0.5006
Epoch 971/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6200 - acc: 0.6511Epoch 00970: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9526 - val_acc: 0.5006
Epoch 972/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6151 - acc: 0.6514Epoch 00971: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9529 - val_acc: 0.5006
Epoch 973/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.5972 - acc: 0.6527Epoch 00972: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9479 - val_acc: 0.4982
Epoch 974/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6274 - acc: 0.6507Epoch 00973: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9544 - val_acc: 0.4970
Epoch 975/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5793 - acc: 0.6537Epoch 00974: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9553 - val_acc: 0.4970
Epoch 976/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5931 - acc: 0.6530Epoch 00975: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9524 - val_acc: 0.4970
Epoch 977/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6019 - acc: 0.6524Epoch 00976: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9525 - val_acc: 0.4970
Epoch 978/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5857 - acc: 0.6534Epoch 00977: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9524 - val_acc: 0.4970
Epoch 979/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5802 - acc: 0.6536Epoch 00978: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9522 - val_acc: 0.4970
Epoch 980/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6127 - acc: 0.6516Epoch 00979: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9533 - val_acc: 0.4970
Epoch 981/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6127 - acc: 0.6518Epoch 00980: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9533 - val_acc: 0.4970
Epoch 982/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6514Epoch 00981: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9529 - val_acc: 0.4970
Epoch 983/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6191 - acc: 0.6512Epoch 00982: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9541 - val_acc: 0.4970
Epoch 984/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.5940 - acc: 0.6529Epoch 00983: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9531 - val_acc: 0.4970
Epoch 985/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.5961 - acc: 0.6528Epoch 00984: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6521 - val_loss: 6.9500 - val_acc: 0.4970
Epoch 986/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.5980 - acc: 0.6525Epoch 00985: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9507 - val_acc: 0.4970
Epoch 987/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6064 - acc: 0.6520Epoch 00986: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9504 - val_acc: 0.4970
Epoch 988/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6004 - acc: 0.6524Epoch 00987: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9515 - val_acc: 0.4982
Epoch 989/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.6116 - acc: 0.6517Epoch 00988: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9517 - val_acc: 0.4982
Epoch 990/1000
6420/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6158 - acc: 0.6516Epoch 00989: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9500 - val_acc: 0.4970
Epoch 991/1000
6570/6680 [============================&gt;.] - ETA: 0s - loss: 5.6250 - acc: 0.6510Epoch 00990: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9496 - val_acc: 0.4970
Epoch 992/1000
6480/6680 [============================&gt;.] - ETA: 0s - loss: 5.6160 - acc: 0.6514Epoch 00991: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9500 - val_acc: 0.4970
Epoch 993/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6247 - acc: 0.6510Epoch 00992: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9498 - val_acc: 0.4970
Epoch 994/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6064 - acc: 0.6520Epoch 00993: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9502 - val_acc: 0.4970
Epoch 995/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6014 - acc: 0.6523Epoch 00994: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9509 - val_acc: 0.4982
Epoch 996/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5777 - acc: 0.6538Epoch 00995: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9510 - val_acc: 0.4982
Epoch 997/1000
6450/6680 [===========================&gt;..] - ETA: 0s - loss: 5.6046 - acc: 0.6521Epoch 00996: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9509 - val_acc: 0.4982
Epoch 998/1000
6510/6680 [============================&gt;.] - ETA: 0s - loss: 5.5951 - acc: 0.6528Epoch 00997: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9511 - val_acc: 0.4982
Epoch 999/1000
6600/6680 [============================&gt;.] - ETA: 0s - loss: 5.5945 - acc: 0.6527Epoch 00998: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6071 - acc: 0.6519 - val_loss: 6.9501 - val_acc: 0.4982
Epoch 1000/1000
6540/6680 [============================&gt;.] - ETA: 0s - loss: 5.6188 - acc: 0.6514Epoch 00999: val_loss did not improve
6680/6680 [==============================] - 1s - loss: 5.6072 - acc: 0.6521 - val_loss: 6.9501 - val_acc: 0.4982
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[183]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;keras.callbacks.History at 0x7fabaea3cef0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Load-the-Model-with-the-Best-Validation-Loss">(IMPLEMENTATION) Load the Model with the Best Validation Loss<a class="anchor-link" href="#(IMPLEMENTATION)-Load-the-Model-with-the-Best-Validation-Loss">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[184]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Load the model weights with the best validation loss.</span>
<span class="n">VGG19_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;/output/weights_15.best.VGG19.hdf5&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Test-the-Model">(IMPLEMENTATION) Test the Model<a class="anchor-link" href="#(IMPLEMENTATION)-Test-the-Model">&#182;</a></h3><p>Try out your model on the test dataset of dog images. Ensure that your test accuracy is greater than 60%.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[185]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Calculate classification accuracy on the test dataset.</span>
<span class="n">VGG19_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">VGG19_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">test_VGG19</span><span class="p">]</span>

<span class="c1"># report test accuracy</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">VGG19_predictions</span><span class="p">)</span><span class="o">==</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_targets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">VGG19_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy: </span><span class="si">%.4f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">test_accuracy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Test accuracy: 50.7177%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="(IMPLEMENTATION)-Predict-Dog-Breed-with-the-Model">(IMPLEMENTATION) Predict Dog Breed with the Model<a class="anchor-link" href="#(IMPLEMENTATION)-Predict-Dog-Breed-with-the-Model">&#182;</a></h3><p>Write a function that takes an image path as input and returns the dog breed (<code>Affenpinscher</code>, <code>Afghan_hound</code>, etc) that is predicted by your model.</p>
<p>Similar to the analogous function in Step 5, your function should have three steps:</p>
<ol>
<li>Extract the bottleneck features corresponding to the chosen CNN model.</li>
<li>Supply the bottleneck features as input to the model to return the predicted vector.  Note that the argmax of this prediction vector gives the index of the predicted dog breed.</li>
<li>Use the <code>dog_names</code> array defined in Step 0 of this notebook to return the corresponding breed.</li>
</ol>
<p>The functions to extract the bottleneck features can be found in <code>extract_bottleneck_features.py</code>, and they have been imported in an earlier code cell.  To obtain the bottleneck features corresponding to your chosen CNN architecture, you need to use the function</p>

<pre><code>extract_{network}

</code></pre>
<p>where <code>{network}</code>, in the above filename, should be one of <code>VGG19</code>, <code>Resnet50</code>, <code>InceptionV3</code>, or <code>Xception</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[186]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Write a function that takes a path to an image as input</span>
<span class="c1">### and returns the dog breed that is predicted by the model.</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="k">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">extract_bottleneck_features</span> <span class="k">import</span> <span class="o">*</span>
<span class="c1">#img_disp = np.array(glob(&#39;/dogImages/dogImages/valid/040.Bulldog/Bulldog_02857.jpg&#39;))</span>
<span class="c1">#print(img_disp)</span>
<span class="c1">#myimg = cv2.imread(img_disp[0])</span>
<span class="c1">#imggray = cv2.cvtColor(myimg, cv2.COLOR_BGR2GRAY)</span>
<span class="c1">#print(imggray)</span>
<span class="c1">#img_disp = cv2.cvtColor(img_disp, cv2.COLOR_BGR2GRAY)</span>

<span class="c1">#plt.imshow(img_disp)</span>
<span class="c1">#myimg = image.load_img(&#39;/dogImages/valid/040.Bulldog/Bulldog_02857.jpg&#39;)</span>


<span class="k">def</span> <span class="nf">VGG19_predict_breed</span><span class="p">(</span><span class="n">img_path</span><span class="p">):</span>
    <span class="c1"># extract bottleneck features</span>
    <span class="n">bottleneck_feature</span> <span class="o">=</span> <span class="n">extract_VGG19</span><span class="p">(</span><span class="n">path_to_tensor</span><span class="p">(</span><span class="n">img_path</span><span class="p">))</span>
    <span class="c1"># obtain predicted vector</span>
    <span class="n">predicted_vector</span> <span class="o">=</span> <span class="n">VGG19_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">bottleneck_feature</span><span class="p">)</span>
    <span class="c1"># return dog breed that is predicted by the model</span>
    <span class="k">return</span> <span class="n">dog_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predicted_vector</span><span class="p">)]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step6'></a></p>
<h2 id="Step-6:-Write-your-Algorithm">Step 6: Write your Algorithm<a class="anchor-link" href="#Step-6:-Write-your-Algorithm">&#182;</a></h2><p>Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,</p>
<ul>
<li>if a <strong>dog</strong> is detected in the image, return the predicted breed.</li>
<li>if a <strong>human</strong> is detected in the image, return the resembling dog breed.</li>
<li>if <strong>neither</strong> is detected in the image, provide output that indicates an error.</li>
</ul>
<p>You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the <code>face_detector</code> and <code>dog_detector</code> functions developed above.  You are <strong>required</strong> to use your CNN from Step 5 to predict dog breed.</p>
<p>Some sample output for our algorithm is provided below, but feel free to design your own user experience!</p>
<p><img src="images/sample_human_output.png" alt="Sample Human Output"></p>
<h3 id="(IMPLEMENTATION)-Write-your-Algorithm">(IMPLEMENTATION) Write your Algorithm<a class="anchor-link" href="#(IMPLEMENTATION)-Write-your-Algorithm">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[187]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### TODO: Write your algorithm.</span>
<span class="c1">### Feel free to use as many code cells as needed.</span>
<span class="n">myimg_path</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Path to your image&#39;</span><span class="p">)</span>
<span class="c1">#myimg_path = &#39;/dogImages/dogImages/valid/040.Bulldog/Bulldog_02857.jpg&#39;</span>
<span class="n">isithuman</span><span class="o">=</span> <span class="n">face_detector</span><span class="p">(</span><span class="n">myimg_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">isithuman</span><span class="p">)</span>
<span class="n">isitdog</span> <span class="o">=</span> <span class="n">dog_detector</span><span class="p">(</span><span class="n">myimg_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">isitdog</span><span class="p">)</span>
<span class="k">if</span> <span class="n">isithuman</span> <span class="o">==</span> <span class="kc">True</span> <span class="p">:</span>
   <span class="c1"># predbreed = VGG19_predict_breed(myimg_path)</span>
    <span class="n">VGG19_predict_breed</span><span class="p">(</span><span class="n">myimg_path</span><span class="p">)</span>
    <span class="c1">#print(isinstance(predbreed))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Hi Human you resemble &quot;</span><span class="p">,</span><span class="n">VGG19_predict_breed</span><span class="p">(</span><span class="n">myimg_path</span><span class="p">))</span>
<span class="k">if</span> <span class="n">isitdog</span> <span class="o">==</span> <span class="kc">True</span> <span class="p">:</span>
   <span class="c1"># predbreed = VGG19_predict_breed(myimg_path)</span>
    <span class="n">VGG19_predict_breed</span><span class="p">(</span><span class="n">myimg_path</span><span class="p">)</span>
    <span class="c1">#print(isinstance(predbreed))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; BowBow you resemble &quot;</span><span class="p">,</span><span class="n">VGG19_predict_breed</span><span class="p">(</span><span class="n">myimg_path</span><span class="p">))</span>
    
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Path to your image/dogImages/dogImages/valid/040.Bulldog/Bulldog_02857.jpg
False
True
 BowBow you resemble  /train/040.Bulldog
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><a id='step7'></a></p>
<h2 id="Step-7:-Test-Your-Algorithm">Step 7: Test Your Algorithm<a class="anchor-link" href="#Step-7:-Test-Your-Algorithm">&#182;</a></h2><p>In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that <strong>you</strong> look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?</p>
<h3 id="(IMPLEMENTATION)-Test-Your-Algorithm-on-Sample-Images!">(IMPLEMENTATION) Test Your Algorithm on Sample Images!<a class="anchor-link" href="#(IMPLEMENTATION)-Test-Your-Algorithm-on-Sample-Images!">&#182;</a></h3><p>Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.</p>
<p><strong>Question 6:</strong> Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm.</p>
<p><strong>Answer:</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[188]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## TODO: Execute your algorithm from Step 6 on</span>
<span class="c1">## at least 6 images on your computer.</span>
<span class="c1">## Feel free to use as many code cells as needed.</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">myfold</span> <span class="o">=</span> <span class="s1">&#39;/harcascades/myimage&#39;</span>
<span class="n">listing</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">myfold</span><span class="p">)</span>
<span class="k">for</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">listing</span><span class="p">:</span>
   <span class="c1"># for f in filenames:</span>
    <span class="c1">#myfile= os.path.join(root, f)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;/harcascades/myimage/&#39;</span><span class="o">+</span><span class="n">filenames</span><span class="p">)</span>  
    <span class="k">if</span> <span class="n">filenames</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.jpg&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">filenames</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.PNG&#39;</span><span class="p">)</span> <span class="p">:</span>
        <span class="c1">#VGG19_predict_breed(&#39;/harcascades/myimage/&#39;+filenames)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dog Breed is : &quot;</span><span class="p">,</span> <span class="n">VGG19_predict_breed</span><span class="p">(</span><span class="s1">&#39;/harcascades/myimage/&#39;</span><span class="o">+</span><span class="n">filenames</span><span class="p">))</span>

    
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>/harcascades/myimage/grumpy cat.PNG
Dog Breed is :  /train/123.Pomeranian
/harcascades/myimage/sidd.PNG
Dog Breed is :  /train/049.Chinese_crested
/harcascades/myimage/catsunglaaes.jpg
Dog Breed is :  /train/048.Chihuahua
/harcascades/myimage/saha.PNG
Dog Breed is :  /train/122.Pointer
/harcascades/myimage/pexels-photo-191340.jpeg
/harcascades/myimage/dog2.PNG
Dog Breed is :  /train/120.Pharaoh_hound
/harcascades/myimage/dog-photo-58997.jpeg
/harcascades/myimage/flower.PNG
Dog Breed is :  /train/069.French_bulldog
/harcascades/myimage/doghorse.jpg
Dog Breed is :  /train/002.Afghan_hound
/harcascades/myimage/dog.PNG
Dog Breed is :  /train/096.Labrador_retriever
/harcascades/myimage/catglass.PNG
Dog Breed is :  /train/084.Icelandic_sheepdog
/harcascades/myimage/ferdinandbull.PNG
Dog Breed is :  /train/078.Great_dane
/harcascades/myimage/human1.jpg
Dog Breed is :  /train/124.Poodle
/harcascades/myimage/cat.PNG
Dog Breed is :  /train/017.Bearded_collie
/harcascades/myimage/human2.jpg
Dog Breed is :  /train/124.Poodle
/harcascades/myimage/cat_eyes_face_218865.jpg
Dog Breed is :  /train/123.Pomeranian
/harcascades/myimage/saharsh1.PNG
Dog Breed is :  /train/090.Italian_greyhound
/harcascades/myimage/.floyddata
/harcascades/myimage/human.PNG
Dog Breed is :  /train/049.Chinese_crested
/harcascades/myimage/car.PNG
Dog Breed is :  /train/035.Boykin_spaniel
/harcascades/myimage/flower.jpg
Dog Breed is :  /train/101.Maltese
/harcascades/myimage/chihuahua-dog-puppy-cute-39317.jpeg
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">I</span> <span class="n">think</span> <span class="n">my</span> <span class="n">output</span> <span class="ow">is</span> <span class="n">better</span> <span class="p">(</span><span class="n">compared</span> <span class="n">to</span> <span class="n">the</span> <span class="n">previous</span> <span class="n">runs</span><span class="p">)</span><span class="o">.</span> <span class="n">The</span> <span class="n">algorithm</span> <span class="n">can</span> <span class="n">benefit</span> 
<span class="mf">1.</span> <span class="n">Augmented</span> <span class="n">training</span> <span class="nb">set</span>
<span class="mf">2.</span> <span class="n">Rescale</span> <span class="n">images</span>
<span class="mf">3.</span> <span class="n">Train</span> <span class="n">on</span> <span class="n">more</span> <span class="n">images</span>
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
